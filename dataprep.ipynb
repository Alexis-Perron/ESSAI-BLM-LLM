{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "64d1a932",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option(\"display.max_seq_items\", None)  \n",
    "pd.set_option(\"display.width\", None)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8750bce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexi\\AppData\\Local\\Temp\\ipykernel_27952\\2691490454.py:1: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  raw_data = pd.read_csv(\"C:/Users/alexi/OneDrive/Documents/école/McGill-FIAM/2025/Hackathon-Final-2025/DATA ASSET MANAGEMENT HACKATHON 2025 FINALS/MAIN DATA and SUPPORTING CODES/ret_sample_update.csv\")\n"
     ]
    }
   ],
   "source": [
    "raw_data = pd.read_csv(\"C:/Users/alexi/OneDrive/Documents/école/McGill-FIAM/2025/Hackathon-Final-2025/DATA ASSET MANAGEMENT HACKATHON 2025 FINALS/MAIN DATA and SUPPORTING CODES/ret_sample_update.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "02942aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = raw_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5f68ae0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for 2005 to 2025, read pickle file get gvkeys into a dictionary and delete the dataframe to free up memory\n",
    "gvkeys_dict = {}\n",
    "for year in range(2005, 2026):\n",
    "    text_data = pd.read_pickle(f\"C:\\\\Users\\\\alexi\\\\OneDrive\\\\Documents\\\\école\\\\McGill-FIAM\\\\2025\\\\Hackathon-Final-2025\\\\DATA ASSET MANAGEMENT HACKATHON 2025 FINALS\\\\TEXT DATA US by YEAR\\\\{year}\\\\text_us_{year}.pkl\")\n",
    "    gvkeys_dict[year] = text_data['gvkey'].unique().tolist()\n",
    "    del text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "98cba08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For every gvkey in the dictionary, filter the data dataframe to only include rows with those gvkeys for the corresponding year\n",
    "filtered_data_list = []\n",
    "for year in range(2005, 2026):\n",
    "    # data from that year contains only gvkeys in gvkeys_dict[year]\n",
    "    filtered_data = data[(data['year'] == year) & (data['gvkey'].isin(gvkeys_dict[year]))]\n",
    "    filtered_data_list.append(filtered_data)\n",
    "\n",
    "# concatenate all filtered dataframes\n",
    "filtered_data = pd.concat(filtered_data_list, ignore_index=True)\n",
    "del filtered_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "38ed4756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep columns: date, excntry, stock_ret, year, month, char_date, market_equity, be_me, ni_me, at_gr1, tangibility, at_be, debt_me, div12m_me, eqpo_me, eqnetis_at, debt_iss, ni_be, profit_sale, gp_at, turnover_126d\n",
    "filtered_data = filtered_data[['date', 'gvkey', 'excntry', 'stock_ret', 'year', 'month', 'char_date', 'market_equity', 'be_me', 'ni_me', 'at_gr1', 'tangibility', 'at_be', 'debt_me', 'div12m_me', 'eqpo_me', 'eqnetis_at', 'dbnetis_at', 'ni_be', 'ebit_sale', 'gp_at', 'turnover_126d']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8da097f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "joining_table = pd.read_csv(\"C:/Users/alexi/OneDrive/Documents/école/McGill-FIAM/2025/Hackathon-Final-2025/DATA ASSET MANAGEMENT HACKATHON 2025 FINALS/MAIN DATA and SUPPORTING CODES/North America Company Name Merge by DataDate-GVKEY-IID.csv\")\n",
    "# rename datadate to date\n",
    "joining_table = joining_table.rename(columns={\"datadate\": \"date\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "54b4c24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexi\\AppData\\Local\\Temp\\ipykernel_27952\\548222945.py:65: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(_attach_tic_conm))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] tic/conm ajoutés via as-of join (searchsorted). Couverture tic: 0.9988042938577472\n"
     ]
    }
   ],
   "source": [
    "# === Ajout de 'tic' et 'conm' de façon robuste (week-ends / jours fériés) ===\n",
    "# Problème: 'char_date' peut tomber sur un week-end / jour férié (ex: 2021-02-28, 2021-05-31),\n",
    "# alors que joining_table est souvent indexée sur le dernier jour *ouvrable* du mois.\n",
    "# Un merge exact sur la date peut donc échouer et créer des mois manquants.\n",
    "#\n",
    "# Solution: pour chaque (gvkey, char_date), prendre la dernière ligne de joining_table\n",
    "# dont joining_table.date <= char_date (as-of join), en utilisant np.searchsorted (robuste, rapide),\n",
    "# au lieu de pd.merge_asof (qui impose une contrainte de tri très stricte).\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "fd = filtered_data.copy()\n",
    "fd[\"_row_id\"] = np.arange(len(fd))\n",
    "\n",
    "# Keys côté filtered_data\n",
    "fd[\"gvkey_key\"] = pd.to_numeric(fd[\"gvkey\"], errors=\"coerce\")\n",
    "fd[\"char_date_key\"] = pd.to_datetime(fd[\"char_date\"].astype(str), format=\"%Y%m%d\", errors=\"coerce\")\n",
    "\n",
    "# Keys côté joining_table\n",
    "jt = joining_table[[\"gvkey\", \"date\", \"tic\", \"conm\"]].copy()\n",
    "jt[\"gvkey_key\"] = pd.to_numeric(jt[\"gvkey\"], errors=\"coerce\")\n",
    "jt[\"jt_date_key\"] = pd.to_datetime(jt[\"date\"], errors=\"coerce\")\n",
    "\n",
    "jt = jt.dropna(subset=[\"gvkey_key\", \"jt_date_key\"]).copy()\n",
    "jt = (jt.sort_values([\"gvkey_key\", \"jt_date_key\"])\n",
    "        .drop_duplicates([\"gvkey_key\", \"jt_date_key\"], keep=\"last\")\n",
    "        .reset_index(drop=True))\n",
    "\n",
    "# Grouper les lignes de joining_table par gvkey pour lookup rapide\n",
    "jt_groups = {k: g.reset_index(drop=True) for k, g in jt.groupby(\"gvkey_key\", sort=False)}\n",
    "\n",
    "def _attach_tic_conm(g: pd.DataFrame) -> pd.DataFrame:\n",
    "    t = jt_groups.get(g.name)\n",
    "    if t is None or t.empty:\n",
    "        g[\"tic\"] = pd.NA\n",
    "        g[\"conm\"] = pd.NA\n",
    "        return g\n",
    "\n",
    "    rdates = t[\"jt_date_key\"].to_numpy()\n",
    "    ldates = g[\"char_date_key\"].to_numpy()\n",
    "\n",
    "    pos = np.searchsorted(rdates, ldates, side=\"right\") - 1\n",
    "\n",
    "    tic = np.full(len(g), pd.NA, dtype=object)\n",
    "    conm = np.full(len(g), pd.NA, dtype=object)\n",
    "\n",
    "    ok = pos >= 0\n",
    "    if ok.any():\n",
    "        sel = pos[ok]\n",
    "        tic[ok] = t.loc[sel, \"tic\"].to_numpy()\n",
    "        conm[ok] = t.loc[sel, \"conm\"].to_numpy()\n",
    "\n",
    "    g[\"tic\"] = tic\n",
    "    g[\"conm\"] = conm\n",
    "    return g\n",
    "\n",
    "invalid_mask = fd[\"gvkey_key\"].isna() | fd[\"char_date_key\"].isna()\n",
    "fd_invalid = fd.loc[invalid_mask].copy()\n",
    "fd_valid   = fd.loc[~invalid_mask].copy()\n",
    "\n",
    "# Tri à l'intérieur de chaque gvkey\n",
    "fd_valid = fd_valid.sort_values([\"gvkey_key\", \"char_date_key\"])\n",
    "fd_valid = (fd_valid.groupby(\"gvkey_key\", group_keys=False, sort=False)\n",
    "                    .apply(_attach_tic_conm))\n",
    "\n",
    "# Recombiner et restaurer l'ordre original\n",
    "out = pd.concat([fd_valid, fd_invalid], ignore_index=True)\n",
    "out = out.sort_values(\"_row_id\").drop(columns=[\"_row_id\"], errors=\"ignore\")\n",
    "\n",
    "# Nettoyage des clés auxiliaires si tu ne veux pas les garder:\n",
    "# out = out.drop(columns=[\"gvkey_key\", \"char_date_key\"], errors=\"ignore\")\n",
    "\n",
    "filtered_data = out\n",
    "\n",
    "print(\"[OK] tic/conm ajoutés via as-of join (searchsorted). Couverture tic:\", filtered_data[\"tic\"].notna().mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d8d685ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexi\\AppData\\Local\\Temp\\ipykernel_27952\\3118638869.py:1: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  sector_mapping = pd.read_csv(\"C:/Users/alexi/OneDrive/Documents/école/McGill-FIAM/2025/Hackathon-Final-2025/DATA ASSET MANAGEMENT HACKATHON 2025 FINALS/MAIN DATA and SUPPORTING CODES/Sector Info SIC and GIC codes All Countries to merge by GVKEY and Date.csv\")\n"
     ]
    }
   ],
   "source": [
    "sector_mapping = pd.read_csv(\"C:/Users/alexi/OneDrive/Documents/école/McGill-FIAM/2025/Hackathon-Final-2025/DATA ASSET MANAGEMENT HACKATHON 2025 FINALS/MAIN DATA and SUPPORTING CODES/Sector Info SIC and GIC codes All Countries to merge by GVKEY and Date.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3bd56de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data['gvkey_key'] = pd.to_numeric(filtered_data['gvkey'], errors='coerce').astype('Int64')\n",
    "filtered_data['date_key']  = pd.to_datetime(filtered_data['date'].astype(str), format='%Y%m%d', errors='coerce')\n",
    "\n",
    "# --- Keys sector_mapping (date = YYYYMMDD en int) ---\n",
    "sm = sector_mapping[['gvkey','date','gics','sic','naics']].copy()\n",
    "sm['gvkey_key'] = pd.to_numeric(sm['gvkey'], errors='coerce').astype('Int64')\n",
    "sm['date_key']  = pd.to_datetime(sm['date'].astype(str), format='%Y%m%d', errors='coerce')\n",
    "\n",
    "# (optionnel) éviter les duplications si plusieurs lignes par gvkey-date\n",
    "sm = sm.drop_duplicates(subset=['gvkey_key','date_key'])\n",
    "\n",
    "# --- Merge ---\n",
    "filtered_data = filtered_data.merge(\n",
    "    sm[['gvkey_key','date_key','gics','sic','naics']],\n",
    "    on=['gvkey_key','date_key'],\n",
    "    how='left'\n",
    ").drop(columns=['gvkey_key','date_key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b389084c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>gvkey</th>\n",
       "      <th>excntry</th>\n",
       "      <th>stock_ret</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>char_date</th>\n",
       "      <th>market_equity</th>\n",
       "      <th>be_me</th>\n",
       "      <th>ni_me</th>\n",
       "      <th>...</th>\n",
       "      <th>gp_at</th>\n",
       "      <th>turnover_126d</th>\n",
       "      <th>char_date_key</th>\n",
       "      <th>tic</th>\n",
       "      <th>conm</th>\n",
       "      <th>gics</th>\n",
       "      <th>sic</th>\n",
       "      <th>naics</th>\n",
       "      <th>gics_sector_code</th>\n",
       "      <th>gics_sector_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20050228</td>\n",
       "      <td>1243.0</td>\n",
       "      <td>CAN</td>\n",
       "      <td>0.006239</td>\n",
       "      <td>2005</td>\n",
       "      <td>2</td>\n",
       "      <td>20050131</td>\n",
       "      <td>14740.873131</td>\n",
       "      <td>0.806940</td>\n",
       "      <td>0.048776</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132266</td>\n",
       "      <td>0.002816</td>\n",
       "      <td>2005-01-31</td>\n",
       "      <td>AL.Z</td>\n",
       "      <td>ALCAN INC</td>\n",
       "      <td>15104010.0</td>\n",
       "      <td>3350.0</td>\n",
       "      <td>331319.0</td>\n",
       "      <td>15</td>\n",
       "      <td>Materials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20050228</td>\n",
       "      <td>2697.0</td>\n",
       "      <td>CAN</td>\n",
       "      <td>0.219169</td>\n",
       "      <td>2005</td>\n",
       "      <td>2</td>\n",
       "      <td>20050131</td>\n",
       "      <td>5361.886510</td>\n",
       "      <td>0.502860</td>\n",
       "      <td>0.061368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.259079</td>\n",
       "      <td>0.003992</td>\n",
       "      <td>2005-01-31</td>\n",
       "      <td>NXY.PB</td>\n",
       "      <td>NEXEN INC</td>\n",
       "      <td>10102020.0</td>\n",
       "      <td>1311.0</td>\n",
       "      <td>211111.0</td>\n",
       "      <td>10</td>\n",
       "      <td>Energy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20050228</td>\n",
       "      <td>3153.0</td>\n",
       "      <td>CAN</td>\n",
       "      <td>0.135651</td>\n",
       "      <td>2005</td>\n",
       "      <td>2</td>\n",
       "      <td>20050131</td>\n",
       "      <td>844.238381</td>\n",
       "      <td>0.204080</td>\n",
       "      <td>-0.045023</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2005-01-31</td>\n",
       "      <td>CDM.</td>\n",
       "      <td>COEUR MINING INC</td>\n",
       "      <td>15104040.0</td>\n",
       "      <td>1044.0</td>\n",
       "      <td>212222.0</td>\n",
       "      <td>15</td>\n",
       "      <td>Materials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20050228</td>\n",
       "      <td>4040.0</td>\n",
       "      <td>CAN</td>\n",
       "      <td>0.004546</td>\n",
       "      <td>2005</td>\n",
       "      <td>2</td>\n",
       "      <td>20050131</td>\n",
       "      <td>7294.809288</td>\n",
       "      <td>0.595438</td>\n",
       "      <td>0.030264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.191872</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>2005-01-31</td>\n",
       "      <td>RRD.2</td>\n",
       "      <td>DONNELLEY (R R) &amp; SONS CO</td>\n",
       "      <td>20201010.0</td>\n",
       "      <td>2750.0</td>\n",
       "      <td>32311.0</td>\n",
       "      <td>20</td>\n",
       "      <td>Industrials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20050228</td>\n",
       "      <td>4864.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>0.207941</td>\n",
       "      <td>2005</td>\n",
       "      <td>2</td>\n",
       "      <td>20050131</td>\n",
       "      <td>602.468980</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.449718</td>\n",
       "      <td>...</td>\n",
       "      <td>0.118811</td>\n",
       "      <td>0.038071</td>\n",
       "      <td>2005-01-31</td>\n",
       "      <td>FWLT</td>\n",
       "      <td>FOSTER WHEELER AG</td>\n",
       "      <td>20103010.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>236210.0</td>\n",
       "      <td>20</td>\n",
       "      <td>Industrials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636439</th>\n",
       "      <td>20250630</td>\n",
       "      <td>315318.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>0.063407</td>\n",
       "      <td>2025</td>\n",
       "      <td>6</td>\n",
       "      <td>20250530</td>\n",
       "      <td>5184.735520</td>\n",
       "      <td>0.477729</td>\n",
       "      <td>0.046791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.244835</td>\n",
       "      <td>0.010482</td>\n",
       "      <td>2025-05-30</td>\n",
       "      <td>ESI</td>\n",
       "      <td>ELEMENT SOLUTIONS INC</td>\n",
       "      <td>15101050.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>Materials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636440</th>\n",
       "      <td>20250630</td>\n",
       "      <td>316056.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>0.013758</td>\n",
       "      <td>2025</td>\n",
       "      <td>6</td>\n",
       "      <td>20250530</td>\n",
       "      <td>12279.192300</td>\n",
       "      <td>0.122215</td>\n",
       "      <td>0.048660</td>\n",
       "      <td>...</td>\n",
       "      <td>0.397656</td>\n",
       "      <td>0.011089</td>\n",
       "      <td>2025-05-30</td>\n",
       "      <td>ALLE</td>\n",
       "      <td>ALLEGION PLC</td>\n",
       "      <td>20102010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>Industrials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636441</th>\n",
       "      <td>20250630</td>\n",
       "      <td>317264.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>0.138720</td>\n",
       "      <td>2025</td>\n",
       "      <td>6</td>\n",
       "      <td>20250530</td>\n",
       "      <td>913.093680</td>\n",
       "      <td>1.170207</td>\n",
       "      <td>0.176673</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.067016</td>\n",
       "      <td>0.018638</td>\n",
       "      <td>2025-05-30</td>\n",
       "      <td>LPG</td>\n",
       "      <td>DORIAN LPG LTD</td>\n",
       "      <td>10102040.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>Energy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636442</th>\n",
       "      <td>20250630</td>\n",
       "      <td>326688.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>0.113222</td>\n",
       "      <td>2025</td>\n",
       "      <td>6</td>\n",
       "      <td>20250530</td>\n",
       "      <td>10833.048800</td>\n",
       "      <td>0.321267</td>\n",
       "      <td>0.022228</td>\n",
       "      <td>...</td>\n",
       "      <td>0.201206</td>\n",
       "      <td>0.012945</td>\n",
       "      <td>2025-05-30</td>\n",
       "      <td>NVT</td>\n",
       "      <td>NVENT ELECTRIC PLC</td>\n",
       "      <td>20104010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>Industrials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636443</th>\n",
       "      <td>20250630</td>\n",
       "      <td>328795.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>2025</td>\n",
       "      <td>6</td>\n",
       "      <td>20250530</td>\n",
       "      <td>4211.356320</td>\n",
       "      <td>0.624217</td>\n",
       "      <td>0.022249</td>\n",
       "      <td>...</td>\n",
       "      <td>0.144482</td>\n",
       "      <td>0.005832</td>\n",
       "      <td>2025-05-30</td>\n",
       "      <td>ACA</td>\n",
       "      <td>ARCOSA INC</td>\n",
       "      <td>20103010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>Industrials</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>636444 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date     gvkey excntry  stock_ret  year  month  char_date  \\\n",
       "0       20050228    1243.0     CAN   0.006239  2005      2   20050131   \n",
       "1       20050228    2697.0     CAN   0.219169  2005      2   20050131   \n",
       "2       20050228    3153.0     CAN   0.135651  2005      2   20050131   \n",
       "3       20050228    4040.0     CAN   0.004546  2005      2   20050131   \n",
       "4       20050228    4864.0     USA   0.207941  2005      2   20050131   \n",
       "...          ...       ...     ...        ...   ...    ...        ...   \n",
       "636439  20250630  315318.0     USA   0.063407  2025      6   20250530   \n",
       "636440  20250630  316056.0     USA   0.013758  2025      6   20250530   \n",
       "636441  20250630  317264.0     USA   0.138720  2025      6   20250530   \n",
       "636442  20250630  326688.0     USA   0.113222  2025      6   20250530   \n",
       "636443  20250630  328795.0     USA   0.005100  2025      6   20250530   \n",
       "\n",
       "        market_equity     be_me     ni_me  ...     gp_at  turnover_126d  \\\n",
       "0        14740.873131  0.806940  0.048776  ...  0.132266       0.002816   \n",
       "1         5361.886510  0.502860  0.061368  ...  0.259079       0.003992   \n",
       "2          844.238381  0.204080 -0.045023  ...  0.102018            NaN   \n",
       "3         7294.809288  0.595438  0.030264  ...  0.191872       0.000004   \n",
       "4          602.468980       NaN -0.449718  ...  0.118811       0.038071   \n",
       "...               ...       ...       ...  ...       ...            ...   \n",
       "636439    5184.735520  0.477729  0.046791  ...  0.244835       0.010482   \n",
       "636440   12279.192300  0.122215  0.048660  ...  0.397656       0.011089   \n",
       "636441     913.093680  1.170207  0.176673  ... -0.067016       0.018638   \n",
       "636442   10833.048800  0.321267  0.022228  ...  0.201206       0.012945   \n",
       "636443    4211.356320  0.624217  0.022249  ...  0.144482       0.005832   \n",
       "\n",
       "        char_date_key     tic                       conm        gics     sic  \\\n",
       "0          2005-01-31    AL.Z                  ALCAN INC  15104010.0  3350.0   \n",
       "1          2005-01-31  NXY.PB                  NEXEN INC  10102020.0  1311.0   \n",
       "2          2005-01-31    CDM.           COEUR MINING INC  15104040.0  1044.0   \n",
       "3          2005-01-31   RRD.2  DONNELLEY (R R) & SONS CO  20201010.0  2750.0   \n",
       "4          2005-01-31    FWLT          FOSTER WHEELER AG  20103010.0  1600.0   \n",
       "...               ...     ...                        ...         ...     ...   \n",
       "636439     2025-05-30     ESI      ELEMENT SOLUTIONS INC  15101050.0     NaN   \n",
       "636440     2025-05-30    ALLE               ALLEGION PLC  20102010.0     NaN   \n",
       "636441     2025-05-30     LPG             DORIAN LPG LTD  10102040.0     NaN   \n",
       "636442     2025-05-30     NVT         NVENT ELECTRIC PLC  20104010.0     NaN   \n",
       "636443     2025-05-30     ACA                 ARCOSA INC  20103010.0     NaN   \n",
       "\n",
       "           naics  gics_sector_code  gics_sector_name  \n",
       "0       331319.0                15         Materials  \n",
       "1       211111.0                10            Energy  \n",
       "2       212222.0                15         Materials  \n",
       "3        32311.0                20       Industrials  \n",
       "4       236210.0                20       Industrials  \n",
       "...          ...               ...               ...  \n",
       "636439       NaN                15         Materials  \n",
       "636440       NaN                20       Industrials  \n",
       "636441       NaN                10            Energy  \n",
       "636442       NaN                20       Industrials  \n",
       "636443       NaN                20       Industrials  \n",
       "\n",
       "[636444 rows x 30 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Extraire le code secteur GICS (2 premiers chiffres) à partir du code GICS 8 chiffres\n",
    "# ex: 20101010 -> 20\n",
    "filtered_data['gics_sector_code'] = (\n",
    "    pd.to_numeric(filtered_data['gics'], errors='coerce')\n",
    "      .floordiv(10**6)\n",
    "      .astype('Int64')\n",
    ")\n",
    "\n",
    "# 2) Mapping MSCI / GICS (11 secteurs)\n",
    "gics_sector_map = {\n",
    "    10: \"Energy\",\n",
    "    15: \"Materials\",\n",
    "    20: \"Industrials\",\n",
    "    25: \"Consumer Discretionary\",\n",
    "    30: \"Consumer Staples\",\n",
    "    35: \"Health Care\",\n",
    "    40: \"Financials\",\n",
    "    45: \"Information Technology\",\n",
    "    50: \"Communication Services\",\n",
    "    55: \"Utilities\",\n",
    "    60: \"Real Estate\",\n",
    "}\n",
    "\n",
    "# 3) Ajouter le nom du secteur\n",
    "filtered_data['gics_sector_name'] = filtered_data['gics_sector_code'].map(gics_sector_map)\n",
    "filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5f301f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import ast\n",
    "import re\n",
    "\n",
    "# Répertoire (relatif au notebook)\n",
    "SP500_DIR = Path(\"sp500-master/sp500_constituants_2005_2024\")\n",
    "\n",
    "def norm_tic(s):\n",
    "    if pd.isna(s):\n",
    "        return pd.NA\n",
    "    s = str(s).strip().upper()\n",
    "    # optionnel: harmoniser BRK.B vs BRK-B, BF.B vs BF-B, etc.\n",
    "    s = s.replace(\"-\", \".\")\n",
    "    return s\n",
    "\n",
    "# 1) Charger tous les fichiers annuels et construire (year, tic_norm)\n",
    "members = []\n",
    "for fp in sorted(SP500_DIR.glob(\"*-sp500-ticker-list.csv\")):\n",
    "    # année depuis le nom du fichier (ex: 2006-sp500-ticker-list.csv)\n",
    "    year = int(fp.name.split(\"-\")[0])\n",
    "\n",
    "    df = pd.read_csv(fp)\n",
    "    # tickers est une string du type \"['A', 'AAPL', ...]\"\n",
    "    tickers = ast.literal_eval(df.loc[0, \"tickers\"]) if isinstance(df.loc[0, \"tickers\"], str) else df.loc[0, \"tickers\"]\n",
    "    tickers = [norm_tic(t) for t in tickers]\n",
    "\n",
    "    members.append(pd.DataFrame({\"year\": year, \"tic_norm\": tickers}))\n",
    "\n",
    "sp500_members = pd.concat(members, ignore_index=True).dropna().drop_duplicates()\n",
    "\n",
    "# 2) Filtrer filtered_data par année (S&P500 de l'année correspondante)\n",
    "fd = filtered_data.copy()\n",
    "fd[\"tic_norm\"] = fd[\"tic\"].map(norm_tic)\n",
    "\n",
    "filtered_data = (\n",
    "    fd.merge(sp500_members, on=[\"year\", \"tic_norm\"], how=\"inner\")\n",
    "      .drop(columns=[\"tic_norm\"])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8fe27143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward fill values par gvkey, trié par date pour les colonnes: stock_ret, 'market_equity', 'be_me', 'ni_me', 'at_gr1', 'tangibility', 'at_be', 'debt_me', 'div12m_me', 'eqpo_me', 'eqnetis_at', 'dbnetis_at', 'ni_be', 'ebit_sale', 'gp_at', 'turnover_126d', 'gics', 'sic', 'naics', 'gics_sector_code', 'gics_sector_name'\n",
    "filtered_data = filtered_data.sort_values(by=['gvkey', 'date'])\n",
    "cols_to_ffill = ['stock_ret', 'market_equity', 'be_me', 'ni_me', 'at_gr1', 'tangibility', 'at_be', 'debt_me', 'div12m_me', 'eqpo_me', 'eqnetis_at', 'dbnetis_at', 'ni_be', 'ebit_sale', 'gp_at', 'turnover_126d', 'gics', 'sic', 'naics', 'gics_sector_code', 'gics_sector_name']\n",
    "filtered_data[cols_to_ffill] = (filtered_data.groupby('gvkey')[cols_to_ffill].ffill())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d9008247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Réduction de la taille des données\n",
    "# Garder données entre 2020 et 2023 inclus\n",
    "# Éliminer la moitié des tickers\n",
    "\n",
    "filtered_data = filtered_data[(filtered_data['year'] >= 2020) & (filtered_data['year'] <= 2023)]\n",
    "filtered_data = filtered_data.sort_values(by=['gvkey'])\n",
    "# unique_gvkeys = filtered_data['gvkey'].unique()\n",
    "# reduced_gvkeys = unique_gvkeys[::2]  # garder un gvkey sur deux\n",
    "# filtered_data = filtered_data[filtered_data['gvkey'].isin(reduced_gvkeys)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a24dc049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2005: 0 unique tickers\n",
      "Year 2006: 0 unique tickers\n",
      "Year 2007: 0 unique tickers\n",
      "Year 2008: 0 unique tickers\n",
      "Year 2009: 0 unique tickers\n",
      "Year 2010: 0 unique tickers\n",
      "Year 2011: 0 unique tickers\n",
      "Year 2012: 0 unique tickers\n",
      "Year 2013: 0 unique tickers\n",
      "Year 2014: 0 unique tickers\n",
      "Year 2015: 0 unique tickers\n",
      "Year 2016: 0 unique tickers\n",
      "Year 2017: 0 unique tickers\n",
      "Year 2018: 0 unique tickers\n",
      "Year 2019: 0 unique tickers\n",
      "Year 2020: 418 unique tickers\n",
      "Year 2021: 415 unique tickers\n",
      "Year 2022: 419 unique tickers\n",
      "Year 2023: 426 unique tickers\n",
      "Year 2024: 0 unique tickers\n",
      "Year 2025: 0 unique tickers\n"
     ]
    }
   ],
   "source": [
    "# Afficher le nombre de tickers unique par année\n",
    "for year in range(2005, 2026):\n",
    "    n_unique_tickers = filtered_data[filtered_data['year'] == year]['gvkey'].nunique()\n",
    "    print(f\"Year {year}: {n_unique_tickers} unique tickers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarized years found: [2021, 2022, 2023]\n",
      "Added column: summary_json\n",
      "Coverage: 0.7267685851318945\n"
     ]
    }
   ],
   "source": [
    "# === Add latest available summarized filing JSON (summary_json) as-of each monthly observation ===\n",
    "# This reads the summarized pickles created by summarize_text_reports_v3.py (e.g., C:\\TEXT DATA US SUMMARIZED\\2021\\text_us_2021.pkl)\n",
    "# and attaches, for each (gvkey, date) in filtered_data, the most recent filing summary_json with report_date <= date.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- Pickle compatibility (some pickles reference numpy._core) ---\n",
    "try:\n",
    "    import numpy._core as _ncore\n",
    "    sys.modules.setdefault(\"numpy._core\", _ncore)\n",
    "    try:\n",
    "        sys.modules.setdefault(\"numpy._core._multiarray_umath\", _ncore._multiarray_umath)\n",
    "    except Exception:\n",
    "        pass\n",
    "except Exception:\n",
    "    import numpy as _np\n",
    "    sys.modules.setdefault(\"numpy._core\", _np.core)\n",
    "    try:\n",
    "        sys.modules.setdefault(\"numpy._core._multiarray_umath\", _np.core._multiarray_umath)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "TEXT_SUM_ROOT = r\"C:\\TEXT DATA US SUMMARIZED\"\n",
    "\n",
    "def _parse_yyyymmdd(x):\n",
    "    \"\"\"Parse YYYYMMDD-like values (int/str) to pandas.Timestamp.\"\"\"\n",
    "    if pd.isna(x):\n",
    "        return pd.NaT\n",
    "    s = str(x)\n",
    "    s_digits = \"\".join(ch for ch in s if ch.isdigit())\n",
    "    if len(s_digits) == 8:\n",
    "        return pd.to_datetime(s_digits, format=\"%Y%m%d\", errors=\"coerce\")\n",
    "    return pd.to_datetime(s, errors=\"coerce\")\n",
    "\n",
    "# Decide which years to load based on filtered_data\n",
    "min_y = int(pd.to_numeric(filtered_data[\"year\"], errors=\"coerce\").min())\n",
    "max_y = int(pd.to_numeric(filtered_data[\"year\"], errors=\"coerce\").max())\n",
    "\n",
    "parts = []\n",
    "available_years = []\n",
    "for y in range(max(2005, min_y - 1), min(2025, max_y) + 1):\n",
    "    p = os.path.join(TEXT_SUM_ROOT, str(y), f\"text_us_{y}.pkl\")\n",
    "    if os.path.exists(p):\n",
    "        df_y = pd.read_pickle(p)\n",
    "        if \"summary_json\" not in df_y.columns:\n",
    "            continue\n",
    "        available_years.append(y)\n",
    "        tmp = df_y[[\"gvkey\", \"date\", \"summary_json\"]].copy()\n",
    "        tmp[\"gvkey\"] = pd.to_numeric(tmp[\"gvkey\"], errors=\"coerce\")\n",
    "        tmp[\"report_date\"] = tmp[\"date\"].apply(_parse_yyyymmdd)\n",
    "        tmp = tmp.dropna(subset=[\"gvkey\", \"report_date\"]).copy()\n",
    "        parts.append(tmp[[\"gvkey\", \"report_date\", \"summary_json\"]])\n",
    "\n",
    "print(\"Summarized years found:\", available_years)\n",
    "\n",
    "if not parts:\n",
    "    print(\"[WARN] No summarized pickles with summary_json found under:\", TEXT_SUM_ROOT)\n",
    "    if \"summary_json\" not in filtered_data.columns:\n",
    "        filtered_data[\"summary_json\"] = pd.NA\n",
    "else:\n",
    "    filings = pd.concat(parts, ignore_index=True)\n",
    "    filings = filings.sort_values([\"gvkey\", \"report_date\"]).drop_duplicates(subset=[\"gvkey\", \"report_date\"], keep=\"last\")\n",
    "\n",
    "    # Build per-gvkey arrays for fast as-of matching\n",
    "    filing_groups = {}\n",
    "    for gv, g in filings.groupby(\"gvkey\", sort=False):\n",
    "        g = g.sort_values(\"report_date\")\n",
    "        filing_groups[gv] = (\n",
    "            g[\"report_date\"].to_numpy(dtype=\"datetime64[ns]\"),\n",
    "            g[\"summary_json\"].to_numpy(dtype=object),\n",
    "        )\n",
    "\n",
    "    # Prepare filtered_data keys\n",
    "    fd = filtered_data.copy()\n",
    "    fd[\"gvkey_key\"] = pd.to_numeric(fd[\"gvkey\"], errors=\"coerce\")\n",
    "    fd[\"date_dt\"] = fd[\"date\"].apply(_parse_yyyymmdd)\n",
    "    fd[\"__row_id\"] = np.arange(len(fd))\n",
    "\n",
    "    valid = fd.dropna(subset=[\"gvkey_key\", \"date_dt\"])[[\"__row_id\", \"gvkey_key\", \"date_dt\"]].copy()\n",
    "\n",
    "    out = pd.Series(pd.NA, index=fd[\"__row_id\"], dtype=object)\n",
    "\n",
    "    for gv, g in valid.groupby(\"gvkey_key\", sort=False):\n",
    "        bundle = filing_groups.get(gv)\n",
    "        if bundle is None:\n",
    "            continue\n",
    "        rdates, rjson = bundle\n",
    "        ldates = g[\"date_dt\"].to_numpy(dtype=\"datetime64[ns]\")\n",
    "        pos = np.searchsorted(rdates, ldates, side=\"right\") - 1\n",
    "        ok = pos >= 0\n",
    "        if np.any(ok):\n",
    "            rid = g.loc[ok, \"__row_id\"].to_numpy(dtype=int)\n",
    "            out.loc[rid] = rjson[pos[ok]]\n",
    "\n",
    "    fd[\"summary_json\"] = fd[\"__row_id\"].map(out)\n",
    "    fd = fd.drop(columns=[\"gvkey_key\", \"date_dt\", \"__row_id\"], errors=\"ignore\")\n",
    "\n",
    "    filtered_data = fd\n",
    "    print(\"Added column: summary_json\")\n",
    "    print(\"Coverage:\", pd.Series(filtered_data[\"summary_json\"]).notna().mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ddf53c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tickers total: 479\n",
      "Tickers never reach 12 valid months: 10\n",
      "Tickers eligible at some point: 469\n",
      "Rows after conditional eligibility filter: 14,754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexi\\AppData\\Local\\Temp\\ipykernel_27952\\69603739.py:43: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: first_eligible_month(g))\n"
     ]
    }
   ],
   "source": [
    "# ---- params ----\n",
    "MIN_TRAIN_ROWS = 12\n",
    "RET_COL = \"stock_ret\"\n",
    "TIC_COL = \"tic\"\n",
    "YEAR_COL = \"year\"\n",
    "MONTH_COL = \"month\"\n",
    "\n",
    "tmp = filtered_data.copy()\n",
    "\n",
    "# Normalize tickers\n",
    "tmp[TIC_COL] = (tmp[TIC_COL].astype(str).str.strip().str.upper().str.replace(\"-\", \".\", regex=False))\n",
    "\n",
    "# Month key\n",
    "tmp[\"ym\"] = pd.to_datetime(dict(year=tmp[YEAR_COL], month=tmp[MONTH_COL], day=1), errors=\"coerce\")\n",
    "\n",
    "# Choose last obs per (tic, ym) using date if available\n",
    "if \"date\" in tmp.columns:\n",
    "    tmp[\"_date_key\"] = pd.to_datetime(tmp[\"date\"].astype(\"Int64\").astype(str), format=\"%Y%m%d\", errors=\"coerce\")\n",
    "    tmp = tmp.sort_values([TIC_COL, \"ym\", \"_date_key\"])\n",
    "else:\n",
    "    tmp = tmp.sort_values([TIC_COL, \"ym\"])\n",
    "\n",
    "# Monthly panel (one row per ticker-month)\n",
    "m = tmp.drop_duplicates(subset=[TIC_COL, \"ym\"], keep=\"last\").copy()\n",
    "m[\"_ret\"] = pd.to_numeric(m[RET_COL], errors=\"coerce\")\n",
    "m[\"_valid\"] = m[\"_ret\"].notna()\n",
    "\n",
    "def first_eligible_month(g: pd.DataFrame) -> pd.Timestamp:\n",
    "    \"\"\"\n",
    "    Returns the first month (ym) such that the ticker has accumulated\n",
    "    MIN_TRAIN_ROWS valid monthly returns up to that month (inclusive).\n",
    "    If never eligible, returns NaT.\n",
    "    \"\"\"\n",
    "    g = g.sort_values(\"ym\").copy()\n",
    "    g[\"_cum_valid\"] = g[\"_valid\"].cumsum()\n",
    "    ok = g[g[\"_cum_valid\"] >= MIN_TRAIN_ROWS]\n",
    "    if ok.empty:\n",
    "        return pd.NaT\n",
    "    return ok[\"ym\"].iloc[0]\n",
    "\n",
    "elig = (\n",
    "    m.groupby(TIC_COL, as_index=False)\n",
    "     .apply(lambda g: first_eligible_month(g))\n",
    "     .reset_index(drop=True)\n",
    ")\n",
    "elig.columns = [TIC_COL, \"first_eligible_ym\"]\n",
    "\n",
    "# Stats\n",
    "total = elig.shape[0]\n",
    "never = elig[\"first_eligible_ym\"].isna().sum()\n",
    "print(f\"Tickers total: {total}\")\n",
    "print(f\"Tickers never reach {MIN_TRAIN_ROWS} valid months: {never}\")\n",
    "print(f\"Tickers eligible at some point: {total - never}\")\n",
    "\n",
    "# Merge eligibility back to monthly panel, then to original df rows\n",
    "# (we will drop rows earlier than first_eligible_ym)\n",
    "tmp2 = tmp.merge(elig, on=TIC_COL, how=\"left\")\n",
    "\n",
    "# Keep only rows where ticker is eligible and ym >= first_eligible_ym\n",
    "# (tickers that never become eligible are fully removed)\n",
    "tmp2 = tmp2[tmp2[\"first_eligible_ym\"].notna()].copy()\n",
    "tmp2 = tmp2[tmp2[\"ym\"] >= tmp2[\"first_eligible_ym\"]].copy()\n",
    "\n",
    "# Cleanup helper cols\n",
    "tmp2 = tmp2.drop(columns=[c for c in [\"ym\", \"_date_key\", \"first_eligible_ym\"] if c in tmp2.columns])\n",
    "\n",
    "# Assign back\n",
    "filtered_data = tmp2\n",
    "\n",
    "print(f\"Rows after conditional eligibility filter: {filtered_data.shape[0]:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "04e5086f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order by date, gvkey\n",
    "\n",
    "filtered_data = filtered_data.sort_values(by=['date', 'gvkey'])\n",
    "filtered_data.to_csv(\"yfinance/filtered_sp500_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "283686ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>gvkey</th>\n",
       "      <th>excntry</th>\n",
       "      <th>stock_ret</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>char_date</th>\n",
       "      <th>market_equity</th>\n",
       "      <th>be_me</th>\n",
       "      <th>ni_me</th>\n",
       "      <th>...</th>\n",
       "      <th>turnover_126d</th>\n",
       "      <th>char_date_key</th>\n",
       "      <th>tic</th>\n",
       "      <th>conm</th>\n",
       "      <th>gics</th>\n",
       "      <th>sic</th>\n",
       "      <th>naics</th>\n",
       "      <th>gics_sector_code</th>\n",
       "      <th>gics_sector_name</th>\n",
       "      <th>summary_json</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20201230</td>\n",
       "      <td>7228.0</td>\n",
       "      <td>DEU</td>\n",
       "      <td>0.026272</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>20201130</td>\n",
       "      <td>152721.219890</td>\n",
       "      <td>0.336802</td>\n",
       "      <td>0.028839</td>\n",
       "      <td>...</td>\n",
       "      <td>1.580000e-06</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>MDT</td>\n",
       "      <td>MEDTRONIC PLC</td>\n",
       "      <td>35101010.0</td>\n",
       "      <td>3845.0</td>\n",
       "      <td>334510.0</td>\n",
       "      <td>35</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20201230</td>\n",
       "      <td>143357.0</td>\n",
       "      <td>DEU</td>\n",
       "      <td>0.035615</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>20201130</td>\n",
       "      <td>157874.393820</td>\n",
       "      <td>0.102757</td>\n",
       "      <td>0.031356</td>\n",
       "      <td>...</td>\n",
       "      <td>2.800000e-07</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>ACN</td>\n",
       "      <td>ACCENTURE PLC</td>\n",
       "      <td>45102010.0</td>\n",
       "      <td>8742.0</td>\n",
       "      <td>541611.0</td>\n",
       "      <td>45</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20201231</td>\n",
       "      <td>1045.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>0.116065</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>20201130</td>\n",
       "      <td>7186.970218</td>\n",
       "      <td>0.031038</td>\n",
       "      <td>-0.482679</td>\n",
       "      <td>...</td>\n",
       "      <td>1.654277e-01</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>AAL</td>\n",
       "      <td>AMERICAN AIRLINES GROUP INC</td>\n",
       "      <td>20302010.0</td>\n",
       "      <td>4512.0</td>\n",
       "      <td>481111.0</td>\n",
       "      <td>20</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20201231</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>-0.023213</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>20201130</td>\n",
       "      <td>9216.064278</td>\n",
       "      <td>0.841259</td>\n",
       "      <td>0.065086</td>\n",
       "      <td>...</td>\n",
       "      <td>8.592500e-03</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>PNW</td>\n",
       "      <td>PINNACLE WEST CAPITAL CORP</td>\n",
       "      <td>55101010.0</td>\n",
       "      <td>4911.0</td>\n",
       "      <td>2211.0</td>\n",
       "      <td>55</td>\n",
       "      <td>Utilities</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20201231</td>\n",
       "      <td>1078.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>0.011735</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>20201130</td>\n",
       "      <td>191805.017800</td>\n",
       "      <td>0.159422</td>\n",
       "      <td>0.016110</td>\n",
       "      <td>...</td>\n",
       "      <td>3.026440e-03</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>ABT</td>\n",
       "      <td>ABBOTT LABORATORIES</td>\n",
       "      <td>35101010.0</td>\n",
       "      <td>3845.0</td>\n",
       "      <td>334510.0</td>\n",
       "      <td>35</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       date     gvkey excntry  stock_ret  year  month  char_date  \\\n",
       "0  20201230    7228.0     DEU   0.026272  2020     12   20201130   \n",
       "1  20201230  143357.0     DEU   0.035615  2020     12   20201130   \n",
       "2  20201231    1045.0     USA   0.116065  2020     12   20201130   \n",
       "3  20201231    1075.0     USA  -0.023213  2020     12   20201130   \n",
       "4  20201231    1078.0     USA   0.011735  2020     12   20201130   \n",
       "\n",
       "   market_equity     be_me     ni_me  ...  turnover_126d  char_date_key  tic  \\\n",
       "0  152721.219890  0.336802  0.028839  ...   1.580000e-06     2020-11-30  MDT   \n",
       "1  157874.393820  0.102757  0.031356  ...   2.800000e-07     2020-11-30  ACN   \n",
       "2    7186.970218  0.031038 -0.482679  ...   1.654277e-01     2020-11-30  AAL   \n",
       "3    9216.064278  0.841259  0.065086  ...   8.592500e-03     2020-11-30  PNW   \n",
       "4  191805.017800  0.159422  0.016110  ...   3.026440e-03     2020-11-30  ABT   \n",
       "\n",
       "                          conm        gics     sic     naics  \\\n",
       "0                MEDTRONIC PLC  35101010.0  3845.0  334510.0   \n",
       "1                ACCENTURE PLC  45102010.0  8742.0  541611.0   \n",
       "2  AMERICAN AIRLINES GROUP INC  20302010.0  4512.0  481111.0   \n",
       "3   PINNACLE WEST CAPITAL CORP  55101010.0  4911.0    2211.0   \n",
       "4          ABBOTT LABORATORIES  35101010.0  3845.0  334510.0   \n",
       "\n",
       "   gics_sector_code        gics_sector_name  summary_json  \n",
       "0                35             Health Care           NaN  \n",
       "1                45  Information Technology           NaN  \n",
       "2                20             Industrials           NaN  \n",
       "3                55               Utilities           NaN  \n",
       "4                35             Health Care           NaN  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data = pd.read_csv(\"yfinance/filtered_sp500_data.csv\")\n",
    "filtered_data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
