{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110326ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using month: 2024-06-01 -> 2024-06-30\n",
      "Saved returns to: yfinance/returns_2024-06-01_2024-06-30.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexi\\AppData\\Local\\Temp\\ipykernel_9724\\2407970222.py:67: FutureWarning: The default fill_method='pad' in DataFrame.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  returns = data.pct_change().iloc[1:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK (responses.parse). expected_return = -0.9174411971347645\n",
      "Saved response to: responses/gpt_2024-06-01_2024-06-30.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "from datetime import timedelta\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Schema for structured output\n",
    "# -----------------------------\n",
    "class ResearchPaperExtraction(BaseModel):\n",
    "    expected_return: float\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Prompts\n",
    "# -----------------------------\n",
    "def make_system_prompt() -> str:\n",
    "    return (\n",
    "        \"You are a model that predicts stock returns.\\n\"\n",
    "        \"Given a time-series of daily returns as percentage change from the past month,\\n\"\n",
    "        \"predict the average daily return (as a percentage change) for the next month.\\n\"\n",
    "        \"Output ONLY valid JSON matching the provided schema.\"\n",
    "    )\n",
    "\n",
    "def make_user_prompt(ticker: str, pct_change_list: list[float]) -> str:\n",
    "    return f\"Ticker: {ticker}\\npct_change: {pct_change_list}\"\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Main (single-call test)\n",
    "# -----------------------------\n",
    "def main():\n",
    "    # Fail fast if API key is missing\n",
    "    # api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "    api_key = \"\"\n",
    "    if not api_key:\n",
    "        raise RuntimeError(\"Missing OPENAI_API_KEY env var. Set it before running.\")\n",
    "\n",
    "    client = OpenAI(api_key=api_key)\n",
    "\n",
    "    # Create directories if they don't exist\n",
    "    os.makedirs(\"yfinance\", exist_ok=True)\n",
    "    os.makedirs(\"responses\", exist_ok=True)\n",
    "\n",
    "    # Load your S&P 500 table (kept because you had it; not strictly needed for the smoke test)\n",
    "    sp500_table = pd.read_csv(\"sp500-master/2024-sp500-ticker-list.csv\")\n",
    "\n",
    "    # Pick ONE month only (first month in your intended range)\n",
    "    current_date = pd.Timestamp(\"2024-06-01\")  # change if you want\n",
    "    month_start = current_date.strftime(\"%Y-%m-%d\")\n",
    "    month_end = (current_date + pd.DateOffset(months=1) - timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    print(f\"Using month: {month_start} -> {month_end}\")\n",
    "\n",
    "    # Read prices data you previously saved\n",
    "    data_path = f\"yfinance/data_2024-07-01_2024-07-31.csv\"\n",
    "    if not os.path.exists(data_path):\n",
    "        raise FileNotFoundError(\n",
    "            f\"Missing {data_path}. Either generate it with yfinance or point to the right file.\"\n",
    "        )\n",
    "\n",
    "    data = pd.read_csv(data_path, index_col=0, parse_dates=True)\n",
    "\n",
    "    # Compute returns\n",
    "    returns = data.pct_change().iloc[1:]\n",
    "    returns_path = f\"yfinance/returns_{month_start}_{month_end}.csv\"\n",
    "    returns.to_csv(returns_path)\n",
    "    print(f\"Saved returns to: {returns_path}\")\n",
    "\n",
    "    # Pick ONE ticker only (first column)\n",
    "    sp500_tickers = list(returns.columns)\n",
    "    if not sp500_tickers:\n",
    "        raise RuntimeError(\"No tickers found in returns file/columns.\")\n",
    "\n",
    "    ticker = sp500_tickers[0]\n",
    "    pct_change = returns[ticker].dropna().astype(float).tolist()\n",
    "\n",
    "    # Optional: reduce prompt size (keeps last ~21 trading days)\n",
    "    pct_change = pct_change[-21:]\n",
    "\n",
    "    system_prompt = make_system_prompt()\n",
    "    user_prompt = make_user_prompt(ticker, pct_change)\n",
    "\n",
    "    schema = ResearchPaperExtraction.model_json_schema()\n",
    "\n",
    "    # ---- ONE API CALL ----\n",
    "    # Preferred: Responses API + structured parsing when available.\n",
    "    # Structured Outputs with json_schema is supported for gpt-4o-mini snapshots and later. :contentReference[oaicite:0]{index=0}\n",
    "    # Responses API is the recommended API for new projects. :contentReference[oaicite:1]{index=1}\n",
    "    try:\n",
    "        # If your SDK supports .responses.parse, this gives you a typed Pydantic result directly.\n",
    "        response = client.responses.parse(\n",
    "            model=\"gpt-4o-mini-2024-07-18\",\n",
    "            input=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt},\n",
    "            ],\n",
    "            text_format=ResearchPaperExtraction,\n",
    "            timeout=60,\n",
    "        )\n",
    "        parsed = response.output_parsed\n",
    "        expected_return = float(parsed.expected_return)\n",
    "        raw_obj = {\"expected_return\": expected_return}\n",
    "        print(\"OK (responses.parse). expected_return =\", expected_return)\n",
    "\n",
    "    except AttributeError:\n",
    "        # Fallback if your installed SDK version doesn't expose responses.parse:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini-2024-07-18\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt},\n",
    "            ],\n",
    "            response_format={\n",
    "                \"type\": \"json_schema\",\n",
    "                \"json_schema\": {\"name\": \"ResearchPaperExtraction\", \"schema\": schema, \"strict\": True},\n",
    "            },\n",
    "            timeout=60,\n",
    "        )\n",
    "        raw_obj = json.loads(completion.choices[0].message.content)\n",
    "        expected_return = float(raw_obj[\"expected_return\"])\n",
    "        print(\"OK (chat.completions fallback). expected_return =\", expected_return)\n",
    "\n",
    "    # Save response (same structure you used, but only one ticker / one value)\n",
    "    out = {\n",
    "        ticker: {\n",
    "            \"ticker\": ticker,\n",
    "            \"pct_change\": pct_change,\n",
    "            \"expected_return\": [expected_return],  # keep list to match your later pipeline\n",
    "        }\n",
    "    }\n",
    "    out_path = f\"responses/gpt_{month_start}_{month_end}.json\"\n",
    "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(out, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"Saved response to: {out_path}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Fail fast if API key is missing\n",
    "    api_key = \"\"\n",
    "    if not api_key:\n",
    "        raise RuntimeError(\"Missing OPENAI_API_KEY env var. Set it before running.\")\n",
    "\n",
    "    client = OpenAI(api_key=api_key)\n",
    "\n",
    "    # Create directories if they don't exist\n",
    "    os.makedirs(\"yfinance\", exist_ok=True)\n",
    "    os.makedirs(\"responses\", exist_ok=True)\n",
    "\n",
    "    # Load your S&P 500 table (kept because you had it; not strictly needed for the smoke test)\n",
    "    sp500_table = pd.read_csv(\"sp500-master/2024-sp500-ticker-list.csv\")\n",
    "\n",
    "    # Pick ONE month only (first month in your intended range)\n",
    "    current_date = pd.Timestamp(\"2024-06-01\")  # change if you want\n",
    "    month_start = current_date.strftime(\"%Y-%m-%d\")\n",
    "    month_end = (current_date + pd.DateOffset(months=1) - timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    print(f\"Using month: {month_start} -> {month_end}\")\n",
    "\n",
    "    # Read prices data you previously saved\n",
    "    data_path = f\"yfinance/data_{month_start}_{month_end}.csv\"\n",
    "    if not os.path.exists(data_path):\n",
    "        raise FileNotFoundError(\n",
    "            f\"Missing {data_path}. Either generate it with yfinance or point to the right file.\"\n",
    "        )\n",
    "\n",
    "    data = pd.read_csv(data_path, index_col=0, parse_dates=True)\n",
    "\n",
    "    # Compute returns\n",
    "    returns = data.pct_change().iloc[1:]\n",
    "    returns_path = f\"yfinance/returns_{month_start}_{month_end}.csv\"\n",
    "    returns.to_csv(returns_path)\n",
    "    print(f\"Saved returns to: {returns_path}\")\n",
    "\n",
    "    # Pick ONE ticker only (first column)\n",
    "    sp500_tickers = list(returns.columns)\n",
    "    if not sp500_tickers:\n",
    "        raise RuntimeError(\"No tickers found in returns file/columns.\")\n",
    "\n",
    "    ticker = sp500_tickers[0]\n",
    "    pct_change = returns[ticker].dropna().astype(float).tolist()\n",
    "\n",
    "    # Optional: reduce prompt size (keeps last ~21 trading days)\n",
    "    pct_change = pct_change[-21:]\n",
    "\n",
    "    system_prompt = make_system_prompt()\n",
    "    user_prompt = make_user_prompt(ticker, pct_change)\n",
    "\n",
    "    schema = ResearchPaperExtraction.model_json_schema()\n",
    "\n",
    "    # ---- ONE API CALL ----\n",
    "    # Preferred: Responses API + structured parsing when available.\n",
    "    # Structured Outputs with json_schema is supported for gpt-4o-mini snapshots and later. :contentReference[oaicite:0]{index=0}\n",
    "    # Responses API is the recommended API for new projects. :contentReference[oaicite:1]{index=1}\n",
    "    try:\n",
    "        # If your SDK supports .responses.parse, this gives you a typed Pydantic result directly.\n",
    "        response = client.responses.parse(\n",
    "            model=\"gpt-4o-mini-2024-07-18\",\n",
    "            input=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt},\n",
    "            ],\n",
    "            text_format=ResearchPaperExtraction,\n",
    "            timeout=60,\n",
    "        )\n",
    "        parsed = response.output_parsed\n",
    "        expected_return = float(parsed.expected_return)\n",
    "        raw_obj = {\"expected_return\": expected_return}\n",
    "        print(\"OK (responses.parse). expected_return =\", expected_return)\n",
    "\n",
    "    except AttributeError:\n",
    "        # Fallback if your installed SDK version doesn't expose responses.parse:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini-2024-07-18\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt},\n",
    "            ],\n",
    "            response_format={\n",
    "                \"type\": \"json_schema\",\n",
    "                \"json_schema\": {\"name\": \"ResearchPaperExtraction\", \"schema\": schema, \"strict\": True},\n",
    "            },\n",
    "            timeout=60,\n",
    "        )\n",
    "        raw_obj = json.loads(completion.choices[0].message.content)\n",
    "        expected_return = float(raw_obj[\"expected_return\"])\n",
    "        print(\"OK (chat.completions fallback). expected_return =\", expected_return)\n",
    "\n",
    "    # Save response (same structure you used, but only one ticker / one value)\n",
    "    out = {\n",
    "        ticker: {\n",
    "            \"ticker\": ticker,\n",
    "            \"pct_change\": pct_change,\n",
    "            \"expected_return\": [expected_return],  # keep list to match your later pipeline\n",
    "        }\n",
    "    }\n",
    "    out_path = f\"responses/gpt_{month_start}_{month_end}.json\"\n",
    "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(out, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"Saved response to: {out_path}\")\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "379b0ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved returns to: yfinance/data_2024-07-01_2024-07-31.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexi\\AppData\\Local\\Temp\\ipykernel_9724\\52672590.py:13: FutureWarning: The default fill_method='pad' in DataFrame.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  returns = data.pct_change().iloc[1:]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "# Read prices data you previously saved\n",
    "data_path = f\"yfinance/data_2024-07-01_2024-07-31.csv\"\n",
    "if not os.path.exists(data_path):\n",
    "    raise FileNotFoundError(\n",
    "        f\"Missing {data_path}. Either generate it with yfinance or point to the right file.\"\n",
    "    )\n",
    "\n",
    "data = pd.read_csv(data_path, index_col=0, parse_dates=True)\n",
    "\n",
    "# Compute returns\n",
    "returns = data.pct_change().iloc[1:]\n",
    "returns_path = data_path\n",
    "returns.to_csv(returns_path)\n",
    "print(f\"Saved returns to: {returns_path}\")\n",
    "\n",
    "\n",
    "# Pick ONE ticker only (first column)\n",
    "sp500_tickers = list(returns.columns)\n",
    "if not sp500_tickers:\n",
    "    raise RuntimeError(\"No tickers found in returns file/columns.\")\n",
    "\n",
    "ticker = sp500_tickers[0].replace(\"'\", \"\")\n",
    "pct_change = returns[ticker].dropna().astype(float).tolist()\n",
    "\n",
    "# Optional: reduce prompt size (keeps last ~21 trading days)\n",
    "pct_change = pct_change[-21:]\n",
    "\n",
    "system_prompt = make_system_prompt()\n",
    "user_prompt = make_user_prompt(ticker, pct_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "884470b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexi\\AppData\\Local\\Temp\\ipykernel_9724\\2907714160.py:10: FutureWarning: The default fill_method='pad' in DataFrame.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  returns = data.pct_change().iloc[1:]\n"
     ]
    }
   ],
   "source": [
    "data_path = f\"yfinance/data_2024-07-01_2024-07-31.csv\"\n",
    "if not os.path.exists(data_path):\n",
    "    raise FileNotFoundError(\n",
    "        f\"Missing {data_path}. Either generate it with yfinance or point to the right file.\"\n",
    "    )\n",
    "\n",
    "data = pd.read_csv(data_path, index_col=0, parse_dates=True)\n",
    "\n",
    "# Compute returns\n",
    "returns = data.pct_change().iloc[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d238ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "# from scipy.optimize import minimize\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "from datetime import datetime, timedelta\n",
    "from keys import gpt_key\n",
    "class ResearchPaperExtraction(BaseModel):\n",
    "    expected_return: float\n",
    "\n",
    "# make model_name arg parser\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--model_name\", type=str, default=\"gpt\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "\"\"\"\n",
    "model\n",
    "\"\"\"\n",
    "model_name = args.model_name\n",
    "if model_name == 'gpt':\n",
    "    client = OpenAI(\n",
    "        api_key=gpt_key\n",
    "    )\n",
    "\n",
    "\"\"\"\n",
    "data\n",
    "\"\"\"\n",
    "# Create date range from June 2024 to November 2024\n",
    "date_range = pd.date_range(start=\"2024-06-01\", end=\"2024-12-01\", freq='MS')\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs('yfinance', exist_ok=True)\n",
    "os.makedirs('responses', exist_ok=True)\n",
    "\n",
    "# 1. S&P500 ticker data\n",
    "# url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "# tables = pd.read_html(url)[0]  # Wikipedia table data\n",
    "# sp500_table = tables[['Symbol', 'Security', 'GICS Sector', 'GICS Sub-Industry']]\n",
    "\n",
    "sp500_table = pd.read_csv('yfinance/filtered_sp500_data.csv')[['tic', 'conm', 'gics', 'sic', 'stock_ret']]\n",
    "\n",
    "for current_date in tqdm(date_range):\n",
    "    month_start = current_date.strftime('%Y-%m-%d')\n",
    "    month_end = (current_date + pd.DateOffset(months=1) - timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "    print(f\"Processing data for {month_start} - {month_end}\")\n",
    "    \n",
    "    # # Download data using yfinance\n",
    "    # data = yf.download(sp500_table['Symbol'].tolist(), start=month_start, end=month_end)['Close']\n",
    "    # Retrieve stock_ret from sp500_table for the given month\n",
    "    mask = (sp500_table['date_key'] >= month_start) & (sp500_table['date_key'] <= month_end)\n",
    "    data = sp500_table.loc[mask, ['tic', 'date_key', 'stock_ret']]\n",
    "\n",
    "    # Save raw data\n",
    "    data.to_csv(f'yfinance/v2_data_{month_start}_{month_end}.csv')\n",
    "    \n",
    "    # Process returns\n",
    "    returns = data.pivot(index='date_key', columns='tic', values='stock_ret')\n",
    "    returns.to_csv(f'yfinance/v2_returns_{month_start}_{month_end}.csv')\n",
    "    sp500_tickers = returns.columns\n",
    "\n",
    "    # Organize data\n",
    "    data_dict = {}\n",
    "    for ticker in sp500_tickers:\n",
    "        data_dict[ticker] = {\n",
    "            'ticker': ticker,\n",
    "            'Security': sp500_table[sp500_table['tic'] == ticker]['conm'].values[0],\n",
    "            'GICS Sector': sp500_table[sp500_table['tic'] == ticker]['gics'].values[0],\n",
    "            'GICS Sub-Industry': sp500_table[sp500_table['tic'] == ticker]['sic'].values[0],\n",
    "            'pct_change': returns[ticker].tolist()\n",
    "        }\n",
    "\n",
    "    def make_system_prompt():\n",
    "        return \"\"\"You are a language model designed to predict stock returns. Given a time-series of daily returns as percentage change from the past month, along with the following company information in a dictionary:\n",
    "\n",
    "        - symbol: The stock symbol\n",
    "        - company name: The name of the company\n",
    "        - GICS sector: The Global Industry Classification Standard (GICS) sector\n",
    "        - GICS sub-industry: The GICS sub-industry\n",
    "\n",
    "        You should predict the average daily return as a percentage change for the next month. Return a single float value representing the predicted average daily return for the next month. Do not include any additional commentary, explanations, or information. Only output the float value.\n",
    "        \"\"\"\n",
    "\n",
    "    def make_user_prompt(ticker, data_dict):\n",
    "        return f\"\"\"Ticker: {ticker}\n",
    "        Security: {data_dict[ticker]['Security']}\n",
    "        Sector: {data_dict[ticker]['GICS Sector']}\n",
    "        Sub-Industry: {data_dict[ticker]['GICS Sub-Industry']}\n",
    "        pct_change: {data_dict[ticker]['pct_change']}\"\"\"\n",
    "\n",
    "    for ticker in tqdm(sp500_tickers):\n",
    "        print(\"=\"*80)\n",
    "        print(ticker)\n",
    "        print(\"=\"*80)\n",
    "        security = data_dict[ticker]['Security']\n",
    "        sector = data_dict[ticker]['GICS Sector']\n",
    "        sub_industry = data_dict[ticker]['GICS Sub-Industry']\n",
    "        pct_change = data_dict[ticker]['pct_change']\n",
    "        system_prompt = make_system_prompt()\n",
    "        user_prompt = make_user_prompt(ticker, data_dict)\n",
    "        if model_name == 'gemma':   \n",
    "            # concat system prompt and user prompt (cuz gemma does not support system prompt)\n",
    "            user_prompt = system_prompt + \"\\n\\n\" + user_prompt\n",
    "\n",
    "        # Get responses 30 times, and use the variance of those values as the confidence of the view.\n",
    "        answers = []\n",
    "        for _ in range(30):\n",
    "            if model_name == 'gpt':\n",
    "                completion = client.chat.completions.create(\n",
    "                    model=\"gpt-4o\",\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": system_prompt},\n",
    "                        {\"role\": \"user\", \"content\": user_prompt},\n",
    "                    ],\n",
    "                    extra_body={\"guided_json\": ResearchPaperExtraction.model_json_schema()}\n",
    "                )\n",
    "            try:\n",
    "                expected_return_dict = eval(completion.choices[0].message.content)\n",
    "                print(expected_return_dict)\n",
    "            except:\n",
    "                # print(completion.choices[0].message.content)\n",
    "                continue\n",
    "            answers.append(expected_return_dict['expected_return'])\n",
    "        data_dict[ticker]['expected_return'] = answers\n",
    "\n",
    "    # Save responses for this month\n",
    "    with open(f'responses/{model_name}_{month_start}_{month_end}.json', 'w') as f:\n",
    "        json.dump(data_dict, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
