{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64d1a932",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option(\"display.max_seq_items\", None)  \n",
    "pd.set_option(\"display.width\", None)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8750bce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexi\\AppData\\Local\\Temp\\ipykernel_21812\\2691490454.py:1: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  raw_data = pd.read_csv(\"C:/Users/alexi/OneDrive/Documents/école/McGill-FIAM/2025/Hackathon-Final-2025/DATA ASSET MANAGEMENT HACKATHON 2025 FINALS/MAIN DATA and SUPPORTING CODES/ret_sample_update.csv\")\n"
     ]
    }
   ],
   "source": [
    "raw_data = pd.read_csv(\"C:/Users/alexi/OneDrive/Documents/école/McGill-FIAM/2025/Hackathon-Final-2025/DATA ASSET MANAGEMENT HACKATHON 2025 FINALS/MAIN DATA and SUPPORTING CODES/ret_sample_update.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02942aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = raw_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f68ae0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for 2005 to 2025, read pickle file get gvkeys into a dictionary and delete the dataframe to free up memory\n",
    "gvkeys_dict = {}\n",
    "for year in range(2005, 2026):\n",
    "    text_data = pd.read_pickle(f\"C:\\\\Users\\\\alexi\\\\OneDrive\\\\Documents\\\\école\\\\McGill-FIAM\\\\2025\\\\Hackathon-Final-2025\\\\DATA ASSET MANAGEMENT HACKATHON 2025 FINALS\\\\TEXT DATA US by YEAR\\\\{year}\\\\text_us_{year}.pkl\")\n",
    "    gvkeys_dict[year] = text_data['gvkey'].unique().tolist()\n",
    "    del text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98cba08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For every gvkey in the dictionary, filter the data dataframe to only include rows with those gvkeys for the corresponding year\n",
    "filtered_data_list = []\n",
    "for year in range(2005, 2026):\n",
    "    # data from that year contains only gvkeys in gvkeys_dict[year]\n",
    "    filtered_data = data[(data['year'] == year) & (data['gvkey'].isin(gvkeys_dict[year]))]\n",
    "    filtered_data_list.append(filtered_data)\n",
    "\n",
    "# concatenate all filtered dataframes\n",
    "filtered_data = pd.concat(filtered_data_list, ignore_index=True)\n",
    "del filtered_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38ed4756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep columns: date, excntry, stock_ret, year, month, char_date, market_equity, be_me, ni_me, at_gr1, tangibility, at_be, debt_me, div12m_me, eqpo_me, eqnetis_at, debt_iss, ni_be, profit_sale, gp_at, turnover_126d\n",
    "filtered_data = filtered_data[['date', 'gvkey', 'excntry', 'stock_ret', 'year', 'month', 'char_date', 'market_equity', 'be_me', 'ni_me', 'at_gr1', 'tangibility', 'at_be', 'debt_me', 'div12m_me', 'eqpo_me', 'eqnetis_at', 'dbnetis_at', 'ni_be', 'ebit_sale', 'gp_at', 'turnover_126d']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8da097f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "joining_table = pd.read_csv(\"C:/Users/alexi/OneDrive/Documents/école/McGill-FIAM/2025/Hackathon-Final-2025/DATA ASSET MANAGEMENT HACKATHON 2025 FINALS/MAIN DATA and SUPPORTING CODES/North America Company Name Merge by DataDate-GVKEY-IID.csv\")\n",
    "# rename datadate to date\n",
    "joining_table = joining_table.rename(columns={\"datadate\": \"date\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54b4c24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Keys côté filtered_data ---\n",
    "# NOTE: char_date dans ret_sample_update est souvent un \"trading month-end\" (ex: 2021-01-29),\n",
    "# alors que joining_table peut contenir la fin de mois calendrier (ex: 2021-01-31).\n",
    "# Pour éviter de perdre des mois entiers au merge, on normalise les deux côtés à la FIN DE MOIS CALENDAIRE.\n",
    "filtered_data['gvkey_key'] = pd.to_numeric(filtered_data['gvkey'], errors='coerce').astype('Int64')\n",
    "\n",
    "filtered_data['char_date_key'] = (\n",
    "    pd.to_datetime(filtered_data['char_date'].astype(str), format='%Y%m%d', errors='coerce')\n",
    "      .dt.to_period('M')\n",
    "      .dt.to_timestamp('M')   # month-end calendrier\n",
    ")\n",
    "\n",
    "# --- Keys côté joining_table ---\n",
    "joining_table['gvkey_key'] = pd.to_numeric(joining_table['gvkey'], errors='coerce').astype('Int64')\n",
    "joining_table['char_date_key'] = (\n",
    "    pd.to_datetime(joining_table['date'], errors='coerce')\n",
    "      .dt.to_period('M')\n",
    "      .dt.to_timestamp('M')   # month-end calendrier\n",
    ")\n",
    "\n",
    "# (optionnel) éviter les duplications si plusieurs lignes par gvkey-date\n",
    "joining_table = joining_table.drop_duplicates(subset=['gvkey_key', 'char_date_key'])\n",
    "\n",
    "# --- Merge sur gvkey + char_date_key (month-end calendrier) ---\n",
    "filtered_data = filtered_data.merge(\n",
    "    joining_table[['gvkey_key', 'char_date_key', 'tic', 'conm']],\n",
    "    on=['gvkey_key', 'char_date_key'],\n",
    "    how='left'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8d685ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexi\\AppData\\Local\\Temp\\ipykernel_21812\\3118638869.py:1: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  sector_mapping = pd.read_csv(\"C:/Users/alexi/OneDrive/Documents/école/McGill-FIAM/2025/Hackathon-Final-2025/DATA ASSET MANAGEMENT HACKATHON 2025 FINALS/MAIN DATA and SUPPORTING CODES/Sector Info SIC and GIC codes All Countries to merge by GVKEY and Date.csv\")\n"
     ]
    }
   ],
   "source": [
    "sector_mapping = pd.read_csv(\"C:/Users/alexi/OneDrive/Documents/école/McGill-FIAM/2025/Hackathon-Final-2025/DATA ASSET MANAGEMENT HACKATHON 2025 FINALS/MAIN DATA and SUPPORTING CODES/Sector Info SIC and GIC codes All Countries to merge by GVKEY and Date.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bd56de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Keys côté filtered_data ---\n",
    "filtered_data['gvkey_key'] = pd.to_numeric(filtered_data['gvkey'], errors='coerce').astype('Int64')\n",
    "filtered_data['date_key'] = (\n",
    "    pd.to_datetime(filtered_data['date'].astype(str), format='%Y%m%d', errors='coerce')\n",
    "      .dt.to_period('M')\n",
    "      .dt.to_timestamp('M')   # month-end calendrier\n",
    ")\n",
    "\n",
    "# --- Keys sector_mapping ---\n",
    "# Le fichier SIC/GICS contient souvent 'date' (trading month-end) ET parfois 'eom' (calendar month-end).\n",
    "# On privilégie 'eom' si présent, sinon on retombe sur 'date', puis on normalise en month-end calendrier.\n",
    "cols = [c for c in ['gvkey', 'date', 'eom', 'gics', 'sic', 'naics'] if c in sector_mapping.columns]\n",
    "sm = sector_mapping[cols].copy()\n",
    "\n",
    "sm['gvkey_key'] = pd.to_numeric(sm['gvkey'], errors='coerce').astype('Int64')\n",
    "\n",
    "date_col = 'eom' if 'eom' in sm.columns else 'date'\n",
    "# Supporte int YYYYMMDD, string YYYYMMDD, ou YYYY-MM-DD\n",
    "sm['_raw_date'] = sm[date_col].astype(str).str.replace('-', '').str.slice(0, 8)\n",
    "sm['date_key'] = (\n",
    "    pd.to_datetime(sm['_raw_date'], format='%Y%m%d', errors='coerce')\n",
    "      .dt.to_period('M')\n",
    "      .dt.to_timestamp('M')\n",
    ")\n",
    "\n",
    "sm = sm.drop(columns=['_raw_date'])\n",
    "# éviter duplications\n",
    "sm = sm.drop_duplicates(subset=['gvkey_key', 'date_key'])\n",
    "\n",
    "# --- Merge ---\n",
    "filtered_data = (\n",
    "    filtered_data.merge(\n",
    "        sm[['gvkey_key', 'date_key', 'gics', 'sic', 'naics']],\n",
    "        on=['gvkey_key', 'date_key'],\n",
    "        how='left'\n",
    "    )\n",
    "    .drop(columns=['gvkey_key', 'date_key'])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b389084c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>gvkey</th>\n",
       "      <th>excntry</th>\n",
       "      <th>stock_ret</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>char_date</th>\n",
       "      <th>market_equity</th>\n",
       "      <th>be_me</th>\n",
       "      <th>ni_me</th>\n",
       "      <th>...</th>\n",
       "      <th>gp_at</th>\n",
       "      <th>turnover_126d</th>\n",
       "      <th>char_date_key</th>\n",
       "      <th>tic</th>\n",
       "      <th>conm</th>\n",
       "      <th>gics</th>\n",
       "      <th>sic</th>\n",
       "      <th>naics</th>\n",
       "      <th>gics_sector_code</th>\n",
       "      <th>gics_sector_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20050228</td>\n",
       "      <td>1243.0</td>\n",
       "      <td>CAN</td>\n",
       "      <td>0.006239</td>\n",
       "      <td>2005</td>\n",
       "      <td>2</td>\n",
       "      <td>20050131</td>\n",
       "      <td>14740.873131</td>\n",
       "      <td>0.806940</td>\n",
       "      <td>0.048776</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132266</td>\n",
       "      <td>0.002816</td>\n",
       "      <td>2005-01-31</td>\n",
       "      <td>AL.1</td>\n",
       "      <td>ALCAN INC</td>\n",
       "      <td>15104010.0</td>\n",
       "      <td>3350.0</td>\n",
       "      <td>331319.0</td>\n",
       "      <td>15</td>\n",
       "      <td>Materials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20050228</td>\n",
       "      <td>2697.0</td>\n",
       "      <td>CAN</td>\n",
       "      <td>0.219169</td>\n",
       "      <td>2005</td>\n",
       "      <td>2</td>\n",
       "      <td>20050131</td>\n",
       "      <td>5361.886510</td>\n",
       "      <td>0.502860</td>\n",
       "      <td>0.061368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.259079</td>\n",
       "      <td>0.003992</td>\n",
       "      <td>2005-01-31</td>\n",
       "      <td>NXY</td>\n",
       "      <td>NEXEN INC</td>\n",
       "      <td>10102020.0</td>\n",
       "      <td>1311.0</td>\n",
       "      <td>211111.0</td>\n",
       "      <td>10</td>\n",
       "      <td>Energy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20050228</td>\n",
       "      <td>3153.0</td>\n",
       "      <td>CAN</td>\n",
       "      <td>0.135651</td>\n",
       "      <td>2005</td>\n",
       "      <td>2</td>\n",
       "      <td>20050131</td>\n",
       "      <td>844.238381</td>\n",
       "      <td>0.204080</td>\n",
       "      <td>-0.045023</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2005-01-31</td>\n",
       "      <td>CDE</td>\n",
       "      <td>COEUR MINING INC</td>\n",
       "      <td>15104040.0</td>\n",
       "      <td>1044.0</td>\n",
       "      <td>212222.0</td>\n",
       "      <td>15</td>\n",
       "      <td>Materials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20050228</td>\n",
       "      <td>4040.0</td>\n",
       "      <td>CAN</td>\n",
       "      <td>0.004546</td>\n",
       "      <td>2005</td>\n",
       "      <td>2</td>\n",
       "      <td>20050131</td>\n",
       "      <td>7294.809288</td>\n",
       "      <td>0.595438</td>\n",
       "      <td>0.030264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.191872</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>2005-01-31</td>\n",
       "      <td>RRD</td>\n",
       "      <td>DONNELLEY (R R) &amp; SONS CO</td>\n",
       "      <td>20201010.0</td>\n",
       "      <td>2750.0</td>\n",
       "      <td>32311.0</td>\n",
       "      <td>20</td>\n",
       "      <td>Industrials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20050228</td>\n",
       "      <td>4864.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>0.207941</td>\n",
       "      <td>2005</td>\n",
       "      <td>2</td>\n",
       "      <td>20050131</td>\n",
       "      <td>602.468980</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.449718</td>\n",
       "      <td>...</td>\n",
       "      <td>0.118811</td>\n",
       "      <td>0.038071</td>\n",
       "      <td>2005-01-31</td>\n",
       "      <td>FWLT</td>\n",
       "      <td>FOSTER WHEELER AG</td>\n",
       "      <td>20103010.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>236210.0</td>\n",
       "      <td>20</td>\n",
       "      <td>Industrials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636439</th>\n",
       "      <td>20250630</td>\n",
       "      <td>315318.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>0.063407</td>\n",
       "      <td>2025</td>\n",
       "      <td>6</td>\n",
       "      <td>20250530</td>\n",
       "      <td>5184.735520</td>\n",
       "      <td>0.477729</td>\n",
       "      <td>0.046791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.244835</td>\n",
       "      <td>0.010482</td>\n",
       "      <td>2025-05-31</td>\n",
       "      <td>ESI</td>\n",
       "      <td>ELEMENT SOLUTIONS INC</td>\n",
       "      <td>15101050.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>Materials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636440</th>\n",
       "      <td>20250630</td>\n",
       "      <td>316056.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>0.013758</td>\n",
       "      <td>2025</td>\n",
       "      <td>6</td>\n",
       "      <td>20250530</td>\n",
       "      <td>12279.192300</td>\n",
       "      <td>0.122215</td>\n",
       "      <td>0.048660</td>\n",
       "      <td>...</td>\n",
       "      <td>0.397656</td>\n",
       "      <td>0.011089</td>\n",
       "      <td>2025-05-31</td>\n",
       "      <td>ALLE</td>\n",
       "      <td>ALLEGION PLC</td>\n",
       "      <td>20102010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>Industrials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636441</th>\n",
       "      <td>20250630</td>\n",
       "      <td>317264.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>0.138720</td>\n",
       "      <td>2025</td>\n",
       "      <td>6</td>\n",
       "      <td>20250530</td>\n",
       "      <td>913.093680</td>\n",
       "      <td>1.170207</td>\n",
       "      <td>0.176673</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.067016</td>\n",
       "      <td>0.018638</td>\n",
       "      <td>2025-05-31</td>\n",
       "      <td>LPG</td>\n",
       "      <td>DORIAN LPG LTD</td>\n",
       "      <td>10102040.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>Energy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636442</th>\n",
       "      <td>20250630</td>\n",
       "      <td>326688.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>0.113222</td>\n",
       "      <td>2025</td>\n",
       "      <td>6</td>\n",
       "      <td>20250530</td>\n",
       "      <td>10833.048800</td>\n",
       "      <td>0.321267</td>\n",
       "      <td>0.022228</td>\n",
       "      <td>...</td>\n",
       "      <td>0.201206</td>\n",
       "      <td>0.012945</td>\n",
       "      <td>2025-05-31</td>\n",
       "      <td>NVT</td>\n",
       "      <td>NVENT ELECTRIC PLC</td>\n",
       "      <td>20104010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>Industrials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636443</th>\n",
       "      <td>20250630</td>\n",
       "      <td>328795.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>2025</td>\n",
       "      <td>6</td>\n",
       "      <td>20250530</td>\n",
       "      <td>4211.356320</td>\n",
       "      <td>0.624217</td>\n",
       "      <td>0.022249</td>\n",
       "      <td>...</td>\n",
       "      <td>0.144482</td>\n",
       "      <td>0.005832</td>\n",
       "      <td>2025-05-31</td>\n",
       "      <td>ACA</td>\n",
       "      <td>ARCOSA INC</td>\n",
       "      <td>20103010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>Industrials</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>636444 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date     gvkey excntry  stock_ret  year  month  char_date  \\\n",
       "0       20050228    1243.0     CAN   0.006239  2005      2   20050131   \n",
       "1       20050228    2697.0     CAN   0.219169  2005      2   20050131   \n",
       "2       20050228    3153.0     CAN   0.135651  2005      2   20050131   \n",
       "3       20050228    4040.0     CAN   0.004546  2005      2   20050131   \n",
       "4       20050228    4864.0     USA   0.207941  2005      2   20050131   \n",
       "...          ...       ...     ...        ...   ...    ...        ...   \n",
       "636439  20250630  315318.0     USA   0.063407  2025      6   20250530   \n",
       "636440  20250630  316056.0     USA   0.013758  2025      6   20250530   \n",
       "636441  20250630  317264.0     USA   0.138720  2025      6   20250530   \n",
       "636442  20250630  326688.0     USA   0.113222  2025      6   20250530   \n",
       "636443  20250630  328795.0     USA   0.005100  2025      6   20250530   \n",
       "\n",
       "        market_equity     be_me     ni_me  ...     gp_at  turnover_126d  \\\n",
       "0        14740.873131  0.806940  0.048776  ...  0.132266       0.002816   \n",
       "1         5361.886510  0.502860  0.061368  ...  0.259079       0.003992   \n",
       "2          844.238381  0.204080 -0.045023  ...  0.102018            NaN   \n",
       "3         7294.809288  0.595438  0.030264  ...  0.191872       0.000004   \n",
       "4          602.468980       NaN -0.449718  ...  0.118811       0.038071   \n",
       "...               ...       ...       ...  ...       ...            ...   \n",
       "636439    5184.735520  0.477729  0.046791  ...  0.244835       0.010482   \n",
       "636440   12279.192300  0.122215  0.048660  ...  0.397656       0.011089   \n",
       "636441     913.093680  1.170207  0.176673  ... -0.067016       0.018638   \n",
       "636442   10833.048800  0.321267  0.022228  ...  0.201206       0.012945   \n",
       "636443    4211.356320  0.624217  0.022249  ...  0.144482       0.005832   \n",
       "\n",
       "        char_date_key   tic                       conm        gics     sic  \\\n",
       "0          2005-01-31  AL.1                  ALCAN INC  15104010.0  3350.0   \n",
       "1          2005-01-31   NXY                  NEXEN INC  10102020.0  1311.0   \n",
       "2          2005-01-31   CDE           COEUR MINING INC  15104040.0  1044.0   \n",
       "3          2005-01-31   RRD  DONNELLEY (R R) & SONS CO  20201010.0  2750.0   \n",
       "4          2005-01-31  FWLT          FOSTER WHEELER AG  20103010.0  1600.0   \n",
       "...               ...   ...                        ...         ...     ...   \n",
       "636439     2025-05-31   ESI      ELEMENT SOLUTIONS INC  15101050.0     NaN   \n",
       "636440     2025-05-31  ALLE               ALLEGION PLC  20102010.0     NaN   \n",
       "636441     2025-05-31   LPG             DORIAN LPG LTD  10102040.0     NaN   \n",
       "636442     2025-05-31   NVT         NVENT ELECTRIC PLC  20104010.0     NaN   \n",
       "636443     2025-05-31   ACA                 ARCOSA INC  20103010.0     NaN   \n",
       "\n",
       "           naics  gics_sector_code  gics_sector_name  \n",
       "0       331319.0                15         Materials  \n",
       "1       211111.0                10            Energy  \n",
       "2       212222.0                15         Materials  \n",
       "3        32311.0                20       Industrials  \n",
       "4       236210.0                20       Industrials  \n",
       "...          ...               ...               ...  \n",
       "636439       NaN                15         Materials  \n",
       "636440       NaN                20       Industrials  \n",
       "636441       NaN                10            Energy  \n",
       "636442       NaN                20       Industrials  \n",
       "636443       NaN                20       Industrials  \n",
       "\n",
       "[636444 rows x 30 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Extraire le code secteur GICS (2 premiers chiffres) à partir du code GICS 8 chiffres\n",
    "# ex: 20101010 -> 20\n",
    "filtered_data['gics_sector_code'] = (\n",
    "    pd.to_numeric(filtered_data['gics'], errors='coerce')\n",
    "      .floordiv(10**6)\n",
    "      .astype('Int64')\n",
    ")\n",
    "\n",
    "# 2) Mapping MSCI / GICS (11 secteurs)\n",
    "gics_sector_map = {\n",
    "    10: \"Energy\",\n",
    "    15: \"Materials\",\n",
    "    20: \"Industrials\",\n",
    "    25: \"Consumer Discretionary\",\n",
    "    30: \"Consumer Staples\",\n",
    "    35: \"Health Care\",\n",
    "    40: \"Financials\",\n",
    "    45: \"Information Technology\",\n",
    "    50: \"Communication Services\",\n",
    "    55: \"Utilities\",\n",
    "    60: \"Real Estate\",\n",
    "}\n",
    "\n",
    "# 3) Ajouter le nom du secteur\n",
    "filtered_data['gics_sector_name'] = filtered_data['gics_sector_code'].map(gics_sector_map)\n",
    "filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a49d54c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AL.1', 'NXY', 'CDE', ..., 'BALY', 'USAR', 'FLYYQ'],\n",
       "      shape=(5617,), dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data['tic'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f301f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexi\\AppData\\Local\\Temp\\ipykernel_21812\\2176200038.py:55: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  members.append(pd.DataFrame({'year': year, 'tic_norm': pd.unique(all_tickers)}))\n",
      "C:\\Users\\alexi\\AppData\\Local\\Temp\\ipykernel_21812\\2176200038.py:55: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  members.append(pd.DataFrame({'year': year, 'tic_norm': pd.unique(all_tickers)}))\n",
      "C:\\Users\\alexi\\AppData\\Local\\Temp\\ipykernel_21812\\2176200038.py:55: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  members.append(pd.DataFrame({'year': year, 'tic_norm': pd.unique(all_tickers)}))\n",
      "C:\\Users\\alexi\\AppData\\Local\\Temp\\ipykernel_21812\\2176200038.py:55: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  members.append(pd.DataFrame({'year': year, 'tic_norm': pd.unique(all_tickers)}))\n",
      "C:\\Users\\alexi\\AppData\\Local\\Temp\\ipykernel_21812\\2176200038.py:55: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  members.append(pd.DataFrame({'year': year, 'tic_norm': pd.unique(all_tickers)}))\n",
      "C:\\Users\\alexi\\AppData\\Local\\Temp\\ipykernel_21812\\2176200038.py:55: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  members.append(pd.DataFrame({'year': year, 'tic_norm': pd.unique(all_tickers)}))\n",
      "C:\\Users\\alexi\\AppData\\Local\\Temp\\ipykernel_21812\\2176200038.py:55: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  members.append(pd.DataFrame({'year': year, 'tic_norm': pd.unique(all_tickers)}))\n",
      "C:\\Users\\alexi\\AppData\\Local\\Temp\\ipykernel_21812\\2176200038.py:55: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  members.append(pd.DataFrame({'year': year, 'tic_norm': pd.unique(all_tickers)}))\n",
      "C:\\Users\\alexi\\AppData\\Local\\Temp\\ipykernel_21812\\2176200038.py:55: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  members.append(pd.DataFrame({'year': year, 'tic_norm': pd.unique(all_tickers)}))\n",
      "C:\\Users\\alexi\\AppData\\Local\\Temp\\ipykernel_21812\\2176200038.py:55: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  members.append(pd.DataFrame({'year': year, 'tic_norm': pd.unique(all_tickers)}))\n",
      "C:\\Users\\alexi\\AppData\\Local\\Temp\\ipykernel_21812\\2176200038.py:55: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  members.append(pd.DataFrame({'year': year, 'tic_norm': pd.unique(all_tickers)}))\n",
      "C:\\Users\\alexi\\AppData\\Local\\Temp\\ipykernel_21812\\2176200038.py:55: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  members.append(pd.DataFrame({'year': year, 'tic_norm': pd.unique(all_tickers)}))\n",
      "C:\\Users\\alexi\\AppData\\Local\\Temp\\ipykernel_21812\\2176200038.py:55: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  members.append(pd.DataFrame({'year': year, 'tic_norm': pd.unique(all_tickers)}))\n",
      "C:\\Users\\alexi\\AppData\\Local\\Temp\\ipykernel_21812\\2176200038.py:55: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  members.append(pd.DataFrame({'year': year, 'tic_norm': pd.unique(all_tickers)}))\n",
      "C:\\Users\\alexi\\AppData\\Local\\Temp\\ipykernel_21812\\2176200038.py:55: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  members.append(pd.DataFrame({'year': year, 'tic_norm': pd.unique(all_tickers)}))\n",
      "C:\\Users\\alexi\\AppData\\Local\\Temp\\ipykernel_21812\\2176200038.py:55: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  members.append(pd.DataFrame({'year': year, 'tic_norm': pd.unique(all_tickers)}))\n",
      "C:\\Users\\alexi\\AppData\\Local\\Temp\\ipykernel_21812\\2176200038.py:55: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  members.append(pd.DataFrame({'year': year, 'tic_norm': pd.unique(all_tickers)}))\n",
      "C:\\Users\\alexi\\AppData\\Local\\Temp\\ipykernel_21812\\2176200038.py:55: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  members.append(pd.DataFrame({'year': year, 'tic_norm': pd.unique(all_tickers)}))\n",
      "C:\\Users\\alexi\\AppData\\Local\\Temp\\ipykernel_21812\\2176200038.py:55: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  members.append(pd.DataFrame({'year': year, 'tic_norm': pd.unique(all_tickers)}))\n",
      "C:\\Users\\alexi\\AppData\\Local\\Temp\\ipykernel_21812\\2176200038.py:55: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  members.append(pd.DataFrame({'year': year, 'tic_norm': pd.unique(all_tickers)}))\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import ast\n",
    "import re\n",
    "\n",
    "# Répertoire (relatif au notebook)\n",
    "SP500_DIR = Path(\"sp500-master/sp500_constituants_2005_2024\")\n",
    "\n",
    "def norm_tic(s):\n",
    "    \"\"\"Normalise un ticker pour matcher les listes S&P500.\"\"\"\n",
    "    if pd.isna(s):\n",
    "        return pd.NA\n",
    "    s = str(s).strip().upper()\n",
    "    # Harmoniser BRK.B vs BRK-B, BF.B vs BF-B, etc. (tes fichiers semblent utiliser '.')\n",
    "    s = s.replace(\"-\", \".\")\n",
    "    return s\n",
    "\n",
    "def parse_ticker_list_cell(x):\n",
    "    \"\"\"Parse une cellule du type \"['A', 'AAPL', ...]\" -> list[str].\"\"\"\n",
    "    if pd.isna(x):\n",
    "        return []\n",
    "    if isinstance(x, list):\n",
    "        return [str(t) for t in x]\n",
    "    s = str(x).strip()\n",
    "    # Essaye literal_eval\n",
    "    try:\n",
    "        v = ast.literal_eval(s)\n",
    "        if isinstance(v, list):\n",
    "            return [str(t) for t in v]\n",
    "    except Exception:\n",
    "        pass\n",
    "    # Fallback regex: tout ce qui ressemble à un token alpha-num/./-\n",
    "    return re.findall(r\"[A-Z0-9\\.\\-]+\", s.upper())\n",
    "\n",
    "# 1) Construire une table (year, tic_norm) à partir des fichiers annuels\n",
    "members = []\n",
    "for year in range(2005, 2025):  # tes fichiers sont 2005..2024\n",
    "    fp = SP500_DIR / f\"{year}-sp500-ticker-list.csv\"\n",
    "    if not fp.exists():\n",
    "        continue\n",
    "    dfy = pd.read_csv(fp)\n",
    "    if 'tickers' not in dfy.columns:\n",
    "        continue\n",
    "\n",
    "    # On prend la dernière ligne (souvent la liste à la fin d'année), sinon concat toutes les lignes\n",
    "    # Ici: concat toutes les lignes, puis unique.\n",
    "    all_tickers = []\n",
    "    for x in dfy['tickers'].dropna().tolist():\n",
    "        all_tickers.extend(parse_ticker_list_cell(x))\n",
    "\n",
    "    all_tickers = [norm_tic(t) for t in all_tickers]\n",
    "    all_tickers = [t for t in all_tickers if pd.notna(t)]\n",
    "\n",
    "    if all_tickers:\n",
    "        members.append(pd.DataFrame({'year': year, 'tic_norm': pd.unique(all_tickers)}))\n",
    "\n",
    "sp500_members = pd.concat(members, ignore_index=True).dropna().drop_duplicates()\n",
    "\n",
    "# 2) Filtrer filtered_data par année (S&P500 de l'année correspondante)\n",
    "fd = filtered_data.copy()\n",
    "fd['tic_norm'] = fd['tic'].map(norm_tic)\n",
    "\n",
    "filtered_data = (\n",
    "    fd.merge(sp500_members, on=['year', 'tic_norm'], how='inner')\n",
    "      .drop(columns=['tic_norm'])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1869f4e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>n_rows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>2020</td>\n",
       "      <td>5</td>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>2020</td>\n",
       "      <td>7</td>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>2020</td>\n",
       "      <td>8</td>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>2020</td>\n",
       "      <td>11</td>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>2021</td>\n",
       "      <td>2</td>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>2021</td>\n",
       "      <td>5</td>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>2021</td>\n",
       "      <td>6</td>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>2021</td>\n",
       "      <td>7</td>\n",
       "      <td>431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>2021</td>\n",
       "      <td>8</td>\n",
       "      <td>431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     year  month  n_rows\n",
       "179  2020      1     430\n",
       "180  2020      2     430\n",
       "181  2020      3     430\n",
       "182  2020      4     430\n",
       "183  2020      5     432\n",
       "184  2020      6     432\n",
       "185  2020      7     432\n",
       "186  2020      8     432\n",
       "187  2020      9     432\n",
       "188  2020     10     432\n",
       "189  2020     11     432\n",
       "190  2020     12     433\n",
       "191  2021      1     430\n",
       "192  2021      2     430\n",
       "193  2021      3     430\n",
       "194  2021      4     430\n",
       "195  2021      5     430\n",
       "196  2021      6     430\n",
       "197  2021      7     431\n",
       "198  2021      8     431\n",
       "199  2021      9     431\n",
       "200  2021     10     431\n",
       "201  2021     11     431\n",
       "202  2021     12     431"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Diagnostic: vérifier la couverture mensuelle (utile pour détecter des mois entiers qui disparaissent)\n",
    "month_counts = (filtered_data.groupby([\"year\", \"month\"]).size().reset_index(name=\"n_rows\"))\n",
    "display(month_counts[month_counts[\"year\"].between(2020, 2021)].sort_values([\"year\",\"month\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fe27143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward fill values par gvkey, trié par date pour les colonnes: stock_ret, 'market_equity', 'be_me', 'ni_me', 'at_gr1', 'tangibility', 'at_be', 'debt_me', 'div12m_me', 'eqpo_me', 'eqnetis_at', 'dbnetis_at', 'ni_be', 'ebit_sale', 'gp_at', 'turnover_126d', 'gics', 'sic', 'naics', 'gics_sector_code', 'gics_sector_name'\n",
    "filtered_data = filtered_data.sort_values(by=['gvkey', 'date'])\n",
    "cols_to_ffill = ['stock_ret', 'market_equity', 'be_me', 'ni_me', 'at_gr1', 'tangibility', 'at_be', 'debt_me', 'div12m_me', 'eqpo_me', 'eqnetis_at', 'dbnetis_at', 'ni_be', 'ebit_sale', 'gp_at', 'turnover_126d', 'gics', 'sic', 'naics', 'gics_sector_code', 'gics_sector_name']\n",
    "filtered_data[cols_to_ffill] = (filtered_data.groupby('gvkey')[cols_to_ffill].ffill())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9008247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Réduction de la taille des données\n",
    "# Garder données entre 2021 et 2023 inclus\n",
    "# Éliminer la moitié des tickers\n",
    "\n",
    "filtered_data = filtered_data[(filtered_data['year'] >= 2021) & (filtered_data['year'] <= 2023)]\n",
    "filtered_data = filtered_data.sort_values(by=['gvkey'])\n",
    "unique_gvkeys = filtered_data['gvkey'].unique()\n",
    "reduced_gvkeys = unique_gvkeys[::2]  # garder un gvkey sur deux\n",
    "filtered_data = filtered_data[filtered_data['gvkey'].isin(reduced_gvkeys)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a24dc049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2005: 0 unique tickers\n",
      "Year 2006: 0 unique tickers\n",
      "Year 2007: 0 unique tickers\n",
      "Year 2008: 0 unique tickers\n",
      "Year 2009: 0 unique tickers\n",
      "Year 2010: 0 unique tickers\n",
      "Year 2011: 0 unique tickers\n",
      "Year 2012: 0 unique tickers\n",
      "Year 2013: 0 unique tickers\n",
      "Year 2014: 0 unique tickers\n",
      "Year 2015: 0 unique tickers\n",
      "Year 2016: 0 unique tickers\n",
      "Year 2017: 0 unique tickers\n",
      "Year 2018: 0 unique tickers\n",
      "Year 2019: 0 unique tickers\n",
      "Year 2020: 0 unique tickers\n",
      "Year 2021: 213 unique tickers\n",
      "Year 2022: 218 unique tickers\n",
      "Year 2023: 220 unique tickers\n",
      "Year 2024: 0 unique tickers\n",
      "Year 2025: 0 unique tickers\n"
     ]
    }
   ],
   "source": [
    "# Afficher le nombre de tickers unique par année\n",
    "for year in range(2005, 2026):\n",
    "    n_unique_tickers = filtered_data[filtered_data['year'] == year]['gvkey'].nunique()\n",
    "    print(f\"Year {year}: {n_unique_tickers} unique tickers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22b6b093",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexi\\AppData\\Local\\Temp\\ipykernel_21812\\641770237.py:15: DeprecationWarning: numpy.core is deprecated and has been renamed to numpy._core. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core._multiarray_umath.\n",
      "  sys.modules.setdefault(\"numpy._core._multiarray_umath\", _np.core._multiarray_umath)\n",
      "C:\\Users\\alexi\\AppData\\Local\\Temp\\ipykernel_21812\\641770237.py:16: DeprecationWarning: numpy.core is deprecated and has been renamed to numpy._core. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.multiarray.\n",
      "  sys.modules.setdefault(\"numpy._core.multiarray\", _np.core.multiarray)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added latest_report_date/latest_report_type/latest_report_text to filtered_data.\n",
      "Coverage: 0.9992406024553854\n"
     ]
    }
   ],
   "source": [
    "# === Add latest available (10-K / 10-Q) text for each (gvkey, date) ===\n",
    "# This attaches the most recent filing text (annual/quarterly) available as-of each month-end observation.\n",
    "#\n",
    "# Expected pickle schema includes: date (YYYYMMDD int), gvkey, file_type, mgmt, rf\n",
    "# We build an \"as-of\" merge by gvkey and date.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- Pickle compatibility (some pickles reference numpy._core) ---\n",
    "import numpy as _np\n",
    "sys.modules.setdefault(\"numpy._core\", _np.core)\n",
    "sys.modules.setdefault(\"numpy._core._multiarray_umath\", _np.core._multiarray_umath)\n",
    "sys.modules.setdefault(\"numpy._core.multiarray\", _np.core.multiarray)\n",
    "\n",
    "TEXT_ROOT = r\"C:\\Users\\alexi\\OneDrive\\Documents\\école\\McGill-FIAM\\2025\\Hackathon-Final-2025\\DATA ASSET MANAGEMENT HACKATHON 2025 FINALS\\TEXT DATA US by YEAR\"\n",
    "\n",
    "# Determine year span to load (include 1 extra year for \"as-of\" lookback)\n",
    "min_y = int(pd.to_numeric(filtered_data[\"year\"], errors=\"coerce\").min())\n",
    "max_y = int(pd.to_numeric(filtered_data[\"year\"], errors=\"coerce\").max())\n",
    "start_y = max(2005, min_y - 1)\n",
    "end_y = min(2025, max_y)\n",
    "\n",
    "panel_gvkeys = pd.to_numeric(filtered_data[\"gvkey\"], errors=\"coerce\").dropna().unique()\n",
    "\n",
    "# Parse panel dates\n",
    "panel_date_dt = pd.to_datetime(filtered_data[\"date\"].astype(str), format=\"%Y%m%d\", errors=\"coerce\")\n",
    "panel_max_dt = panel_date_dt.max()\n",
    "\n",
    "text_frames = []\n",
    "for year in range(start_y, end_y + 1):\n",
    "    fp = os.path.join(TEXT_ROOT, str(year), f\"text_us_{year}.pkl\")\n",
    "    if not os.path.exists(fp):\n",
    "        print(f\"[WARN] Missing text file: {fp}\")\n",
    "        continue\n",
    "\n",
    "    t = pd.read_pickle(fp)\n",
    "\n",
    "    # Keep only needed columns if present\n",
    "    keep = [c for c in [\"date\", \"gvkey\", \"file_type\", \"mgmt\", \"rf\"] if c in t.columns]\n",
    "    t = t[keep].copy()\n",
    "\n",
    "    # Basic cleaning\n",
    "    t[\"gvkey\"] = pd.to_numeric(t[\"gvkey\"], errors=\"coerce\")\n",
    "    t = t.dropna(subset=[\"gvkey\"])\n",
    "    t = t[t[\"gvkey\"].isin(panel_gvkeys)].copy()\n",
    "\n",
    "    # report_date\n",
    "    t[\"report_date\"] = pd.to_datetime(t[\"date\"].astype(\"Int64\").astype(str), format=\"%Y%m%d\", errors=\"coerce\")\n",
    "    t = t.dropna(subset=[\"report_date\"])\n",
    "    t = t[t[\"report_date\"] <= panel_max_dt].copy()\n",
    "\n",
    "    # Ensure text columns exist\n",
    "    if \"mgmt\" not in t.columns:\n",
    "        t[\"mgmt\"] = \"\"\n",
    "    if \"rf\" not in t.columns:\n",
    "        t[\"rf\"] = \"\"\n",
    "    t[\"mgmt\"] = t[\"mgmt\"].fillna(\"\").astype(str)\n",
    "    t[\"rf\"] = t[\"rf\"].fillna(\"\").astype(str)\n",
    "\n",
    "    # Combine into one text field (keeps whichever parts are present)\n",
    "    mg = t[\"mgmt\"].str.strip()\n",
    "    rf = t[\"rf\"].str.strip()\n",
    "    t[\"report_text\"] = (mg + \"\\n\\n\" + rf).str.strip()\n",
    "    t.loc[rf.eq(\"\"), \"report_text\"] = mg\n",
    "    t.loc[mg.eq(\"\"), \"report_text\"] = rf\n",
    "    t[\"report_text\"] = t[\"report_text\"].replace(\"\", np.nan)\n",
    "    t = t.dropna(subset=[\"report_text\"])\n",
    "\n",
    "    # Keep only filing types we care about (annual/quarterly)\n",
    "    if \"file_type\" in t.columns:\n",
    "        t[\"file_type\"] = t[\"file_type\"].astype(str)\n",
    "        t = t[t[\"file_type\"].isin([\"10Q\", \"10K\", \"10KSB\"])].copy()\n",
    "    else:\n",
    "        t[\"file_type\"] = \"\"\n",
    "\n",
    "    text_frames.append(t[[\"gvkey\", \"report_date\", \"file_type\", \"report_text\"]])\n",
    "\n",
    "text_df = pd.concat(text_frames, ignore_index=True) if text_frames else pd.DataFrame(\n",
    "    columns=[\"gvkey\", \"report_date\", \"file_type\", \"report_text\"]\n",
    ")\n",
    "\n",
    "# If multiple filings on same day, prefer annual over quarterly\n",
    "type_rank = {\"10Q\": 1, \"10K\": 2, \"10KSB\": 2}\n",
    "text_df[\"type_rank\"] = text_df[\"file_type\"].map(type_rank).fillna(0).astype(int)\n",
    "text_df = text_df.sort_values([\"gvkey\", \"report_date\", \"type_rank\"])\n",
    "text_df = text_df.drop_duplicates([\"gvkey\", \"report_date\"], keep=\"last\")\n",
    "\n",
    "# As-of merge: for each (gvkey, date) take latest report_date <= date\n",
    "filtered_data[\"gvkey\"] = pd.to_numeric(filtered_data[\"gvkey\"], errors=\"coerce\")\n",
    "filtered_data[\"date_dt\"] = pd.to_datetime(filtered_data[\"date\"].astype(str), format=\"%Y%m%d\", errors=\"coerce\")\n",
    "\n",
    "filtered_data = filtered_data.dropna(subset=[\"date_dt\", \"gvkey\"]).sort_values([\"date_dt\", \"gvkey\"]).reset_index(drop=True)\n",
    "text_df = text_df.sort_values([\"report_date\", \"gvkey\"])\n",
    "\n",
    "filtered_data = pd.merge_asof(\n",
    "    filtered_data,\n",
    "    text_df[[\"gvkey\", \"report_date\", \"file_type\", \"report_text\"]],\n",
    "    left_on=\"date_dt\",\n",
    "    right_on=\"report_date\",\n",
    "    by=\"gvkey\",\n",
    "    direction=\"backward\",\n",
    ")\n",
    "\n",
    "filtered_data = filtered_data.rename(\n",
    "    columns={\n",
    "        \"report_date\": \"latest_report_date\",\n",
    "        \"file_type\": \"latest_report_type\",\n",
    "        \"report_text\": \"latest_report_text\",\n",
    "    }\n",
    ")\n",
    "\n",
    "filtered_data = filtered_data.drop(columns=[\"date_dt\"], errors=\"ignore\")\n",
    "\n",
    "print(\"Added latest_report_date/latest_report_type/latest_report_text to filtered_data.\")\n",
    "print(\"Coverage:\", filtered_data[\"latest_report_text\"].notna().mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd426ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>gvkey</th>\n",
       "      <th>excntry</th>\n",
       "      <th>stock_ret</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>char_date</th>\n",
       "      <th>market_equity</th>\n",
       "      <th>be_me</th>\n",
       "      <th>ni_me</th>\n",
       "      <th>...</th>\n",
       "      <th>tic</th>\n",
       "      <th>conm</th>\n",
       "      <th>gics</th>\n",
       "      <th>sic</th>\n",
       "      <th>naics</th>\n",
       "      <th>gics_sector_code</th>\n",
       "      <th>gics_sector_name</th>\n",
       "      <th>latest_report_date</th>\n",
       "      <th>latest_report_type</th>\n",
       "      <th>latest_report_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20210129</td>\n",
       "      <td>1045.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>0.088776</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>20201231</td>\n",
       "      <td>9800.739885</td>\n",
       "      <td>0.031038</td>\n",
       "      <td>-0.353953</td>\n",
       "      <td>...</td>\n",
       "      <td>AAL</td>\n",
       "      <td>AMERICAN AIRLINES GROUP INC</td>\n",
       "      <td>20302010.0</td>\n",
       "      <td>4512.0</td>\n",
       "      <td>481111.0</td>\n",
       "      <td>20</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>2020-10-22</td>\n",
       "      <td>10Q</td>\n",
       "      <td>Item 1A. Risk Factors \\n 90 Item 1A. Risk Fact...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20210129</td>\n",
       "      <td>1078.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>0.132889</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>20201231</td>\n",
       "      <td>194055.911590</td>\n",
       "      <td>0.157573</td>\n",
       "      <td>0.015923</td>\n",
       "      <td>...</td>\n",
       "      <td>ABT</td>\n",
       "      <td>ABBOTT LABORATORIES</td>\n",
       "      <td>35101010.0</td>\n",
       "      <td>3845.0</td>\n",
       "      <td>334510.0</td>\n",
       "      <td>35</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>2020-11-04</td>\n",
       "      <td>10Q</td>\n",
       "      <td>Item 2. Management s Discussion and Analysis o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20210129</td>\n",
       "      <td>1209.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>-0.023644</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>20201231</td>\n",
       "      <td>60395.008050</td>\n",
       "      <td>0.208648</td>\n",
       "      <td>0.031748</td>\n",
       "      <td>...</td>\n",
       "      <td>APD</td>\n",
       "      <td>AIR PRODUCTS &amp; CHEMICALS INC</td>\n",
       "      <td>15101040.0</td>\n",
       "      <td>2810.0</td>\n",
       "      <td>325120.0</td>\n",
       "      <td>15</td>\n",
       "      <td>Materials</td>\n",
       "      <td>2020-11-19</td>\n",
       "      <td>10K</td>\n",
       "      <td>ITEM 7. MANAGEMENT S DISCUSSION AND ANALYSIS O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20210129</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>-0.081476</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>20201231</td>\n",
       "      <td>149248.610060</td>\n",
       "      <td>0.131378</td>\n",
       "      <td>0.039183</td>\n",
       "      <td>...</td>\n",
       "      <td>HON</td>\n",
       "      <td>HONEYWELL INTERNATIONAL INC</td>\n",
       "      <td>20105010.0</td>\n",
       "      <td>9997.0</td>\n",
       "      <td>999977.0</td>\n",
       "      <td>20</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>2020-10-30</td>\n",
       "      <td>10Q</td>\n",
       "      <td>Item 2. \\n Management s Discussion and Analysi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20210129</td>\n",
       "      <td>1380.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>0.022542</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>20201231</td>\n",
       "      <td>16210.595111</td>\n",
       "      <td>0.414174</td>\n",
       "      <td>-0.196600</td>\n",
       "      <td>...</td>\n",
       "      <td>HES</td>\n",
       "      <td>HESS CORP</td>\n",
       "      <td>10102020.0</td>\n",
       "      <td>1311.0</td>\n",
       "      <td>2111.0</td>\n",
       "      <td>10</td>\n",
       "      <td>Energy</td>\n",
       "      <td>2020-11-05</td>\n",
       "      <td>10Q</td>\n",
       "      <td>Item 1A. Risk Factors. Item 1A. Risk Factors i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       date   gvkey excntry  stock_ret  year  month  char_date  market_equity  \\\n",
       "0  20210129  1045.0     USA   0.088776  2021      1   20201231    9800.739885   \n",
       "1  20210129  1078.0     USA   0.132889  2021      1   20201231  194055.911590   \n",
       "2  20210129  1209.0     USA  -0.023644  2021      1   20201231   60395.008050   \n",
       "3  20210129  1300.0     USA  -0.081476  2021      1   20201231  149248.610060   \n",
       "4  20210129  1380.0     USA   0.022542  2021      1   20201231   16210.595111   \n",
       "\n",
       "      be_me     ni_me  ...  tic                          conm        gics  \\\n",
       "0  0.031038 -0.353953  ...  AAL   AMERICAN AIRLINES GROUP INC  20302010.0   \n",
       "1  0.157573  0.015923  ...  ABT           ABBOTT LABORATORIES  35101010.0   \n",
       "2  0.208648  0.031748  ...  APD  AIR PRODUCTS & CHEMICALS INC  15101040.0   \n",
       "3  0.131378  0.039183  ...  HON   HONEYWELL INTERNATIONAL INC  20105010.0   \n",
       "4  0.414174 -0.196600  ...  HES                     HESS CORP  10102020.0   \n",
       "\n",
       "      sic     naics  gics_sector_code  gics_sector_name  latest_report_date  \\\n",
       "0  4512.0  481111.0                20       Industrials          2020-10-22   \n",
       "1  3845.0  334510.0                35       Health Care          2020-11-04   \n",
       "2  2810.0  325120.0                15         Materials          2020-11-19   \n",
       "3  9997.0  999977.0                20       Industrials          2020-10-30   \n",
       "4  1311.0    2111.0                10            Energy          2020-11-05   \n",
       "\n",
       "   latest_report_type                                 latest_report_text  \n",
       "0                 10Q  Item 1A. Risk Factors \\n 90 Item 1A. Risk Fact...  \n",
       "1                 10Q  Item 2. Management s Discussion and Analysis o...  \n",
       "2                 10K  ITEM 7. MANAGEMENT S DISCUSSION AND ANALYSIS O...  \n",
       "3                 10Q  Item 2. \\n Management s Discussion and Analysi...  \n",
       "4                 10Q  Item 1A. Risk Factors. Item 1A. Risk Factors i...  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "04e5086f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data.to_csv(\"yfinance/filtered_sp500_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76c3a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92794b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data['date'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735160a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
